2024-04-01 08:58:29 | ERROR | stderr | [32mINFO[0m:     Started server process [[36m13485[0m]
2024-04-01 08:58:29 | ERROR | stderr | [32mINFO[0m:     Waiting for application startup.
2024-04-01 08:58:29 | ERROR | stderr | [32mINFO[0m:     Application startup complete.
2024-04-01 08:58:29 | ERROR | stderr | [32mINFO[0m:     Uvicorn running on [1mhttp://localhost:21001[0m (Press CTRL+C to quit)
2024-04-01 09:00:42 | ERROR | stderr | Loading checkpoint shards:   0%|                                                               | 0/2 [00:00<?, ?it/s]
2024-04-01 09:00:44 | ERROR | stderr | Loading checkpoint shards:   0%|                                                               | 0/2 [00:02<?, ?it/s]
2024-04-01 09:00:44 | ERROR | stderr | 
2024-04-01 09:00:44 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 09:00:44 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/llava/model_worker.py", line 271, in <module>
2024-04-01 09:00:44 | ERROR | stderr |     worker = ModelWorker(args.controller_address,
2024-04-01 09:00:44 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/llava/model_worker.py", line 61, in __init__
2024-04-01 09:00:44 | ERROR | stderr |     self.tokenizer, self.model, self.image_processor, self.context_len = load_pretrained_model(
2024-04-01 09:00:44 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/llava/model/builder.py", line 106, in load_pretrained_model
2024-04-01 09:00:44 | ERROR | stderr |     model = LlavaLlamaForCausalLM.from_pretrained(model_path, low_cpu_mem_usage=True, **kwargs)
2024-04-01 09:00:44 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/transformers/modeling_utils.py", line 2903, in from_pretrained
2024-04-01 09:00:44 | ERROR | stderr |     ) = cls._load_pretrained_model(
2024-04-01 09:00:44 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3246, in _load_pretrained_model
2024-04-01 09:00:44 | ERROR | stderr |     state_dict = load_state_dict(shard_file)
2024-04-01 09:00:44 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/transformers/modeling_utils.py", line 460, in load_state_dict
2024-04-01 09:00:44 | ERROR | stderr |     return torch.load(checkpoint_file, map_location="cpu")
2024-04-01 09:00:44 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/torch/serialization.py", line 809, in load
2024-04-01 09:00:44 | ERROR | stderr |     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
2024-04-01 09:00:44 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/torch/serialization.py", line 1172, in _load
2024-04-01 09:00:44 | ERROR | stderr |     result = unpickler.load()
2024-04-01 09:00:44 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/torch/serialization.py", line 1142, in persistent_load
2024-04-01 09:00:44 | ERROR | stderr |     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
2024-04-01 09:00:44 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/torch/serialization.py", line 1112, in load_tensor
2024-04-01 09:00:44 | ERROR | stderr |     storage = zip_file.get_storage_from_record(name, numel, torch.UntypedStorage)._typed_storage()._untyped_storage
2024-04-01 09:00:44 | ERROR | stderr | KeyboardInterrupt
2024-04-01 09:01:02 | WARNING | transformers.models.llama.tokenization_llama | You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
2024-04-01 09:01:03 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 09:01:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/transformers/configuration_utils.py", line 702, in _get_config_dict
2024-04-01 09:01:03 | ERROR | stderr |     config_dict = cls._dict_from_json_file(resolved_config_file)
2024-04-01 09:01:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/transformers/configuration_utils.py", line 793, in _dict_from_json_file
2024-04-01 09:01:03 | ERROR | stderr |     text = reader.read()
2024-04-01 09:01:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/codecs.py", line 322, in decode
2024-04-01 09:01:03 | ERROR | stderr |     (result, consumed) = self._buffer_decode(data, self.errors, final)
2024-04-01 09:01:03 | ERROR | stderr | UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 128: invalid start byte
2024-04-01 09:01:03 | ERROR | stderr | 
2024-04-01 09:01:03 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-01 09:01:03 | ERROR | stderr | 
2024-04-01 09:01:03 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 09:01:03 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/llava/model_worker.py", line 271, in <module>
2024-04-01 09:01:03 | ERROR | stderr |     worker = ModelWorker(args.controller_address,
2024-04-01 09:01:03 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/llava/model_worker.py", line 61, in __init__
2024-04-01 09:01:03 | ERROR | stderr |     self.tokenizer, self.model, self.image_processor, self.context_len = load_pretrained_model(
2024-04-01 09:01:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/llava/model/builder.py", line 106, in load_pretrained_model
2024-04-01 09:01:03 | ERROR | stderr |     model = LlavaLlamaForCausalLM.from_pretrained(model_path, low_cpu_mem_usage=True, **kwargs)
2024-04-01 09:01:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/transformers/modeling_utils.py", line 2700, in from_pretrained
2024-04-01 09:01:03 | ERROR | stderr |     model = cls(config, *model_args, **model_kwargs)
2024-04-01 09:01:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/llava/model/language_model/llava_llama.py", line 45, in __init__
2024-04-01 09:01:03 | ERROR | stderr |     self.model = LlavaLlamaModel(config)
2024-04-01 09:01:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/llava/model/language_model/llava_llama.py", line 37, in __init__
2024-04-01 09:01:03 | ERROR | stderr |     super(LlavaLlamaModel, self).__init__(config)
2024-04-01 09:01:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/llava/model/llava_arch.py", line 33, in __init__
2024-04-01 09:01:03 | ERROR | stderr |     self.vision_tower = build_vision_tower(config, delay_load=True)
2024-04-01 09:01:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/llava/model/multimodal_encoder/builder.py", line 9, in build_vision_tower
2024-04-01 09:01:03 | ERROR | stderr |     return CLIPVisionTower(vision_tower, args=vision_tower_cfg, **kwargs)
2024-04-01 09:01:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/llava/model/multimodal_encoder/clip_encoder.py", line 20, in __init__
2024-04-01 09:01:03 | ERROR | stderr |     self.cfg_only = CLIPVisionConfig.from_pretrained(self.vision_tower_name)
2024-04-01 09:01:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/transformers/models/clip/configuration_clip.py", line 239, in from_pretrained
2024-04-01 09:01:03 | ERROR | stderr |     config_dict, kwargs = cls.get_config_dict(pretrained_model_name_or_path, **kwargs)
2024-04-01 09:01:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/transformers/configuration_utils.py", line 617, in get_config_dict
2024-04-01 09:01:03 | ERROR | stderr |     config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
2024-04-01 09:01:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/transformers/configuration_utils.py", line 705, in _get_config_dict
2024-04-01 09:01:03 | ERROR | stderr |     raise EnvironmentError(
2024-04-01 09:01:03 | ERROR | stderr | OSError: It looks like the config file at '../weights/LLaVA-7b-pretrain-projector-v0-CC3M-595K-original_caption.bin' is not a valid JSON file.
2024-04-01 09:14:38 | WARNING | transformers.models.llama.tokenization_llama | You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
2024-04-01 09:14:38 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 09:14:38 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/llava/model_worker.py", line 271, in <module>
2024-04-01 09:14:38 | ERROR | stderr |     worker = ModelWorker(args.controller_address,
2024-04-01 09:14:38 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/llava/model_worker.py", line 61, in __init__
2024-04-01 09:14:38 | ERROR | stderr |     self.tokenizer, self.model, self.image_processor, self.context_len = load_pretrained_model(
2024-04-01 09:14:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/llava/model/builder.py", line 106, in load_pretrained_model
2024-04-01 09:14:38 | ERROR | stderr |     model = LlavaLlamaForCausalLM.from_pretrained(model_path, low_cpu_mem_usage=True, **kwargs)
2024-04-01 09:14:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/transformers/modeling_utils.py", line 2700, in from_pretrained
2024-04-01 09:14:38 | ERROR | stderr |     model = cls(config, *model_args, **model_kwargs)
2024-04-01 09:14:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/llava/model/language_model/llava_llama.py", line 45, in __init__
2024-04-01 09:14:38 | ERROR | stderr |     self.model = LlavaLlamaModel(config)
2024-04-01 09:14:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/llava/model/language_model/llava_llama.py", line 37, in __init__
2024-04-01 09:14:38 | ERROR | stderr |     super(LlavaLlamaModel, self).__init__(config)
2024-04-01 09:14:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/llava/model/llava_arch.py", line 33, in __init__
2024-04-01 09:14:38 | ERROR | stderr |     self.vision_tower = build_vision_tower(config, delay_load=True)
2024-04-01 09:14:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/llava/model/multimodal_encoder/builder.py", line 11, in build_vision_tower
2024-04-01 09:14:38 | ERROR | stderr |     raise ValueError(f'Unknown vision tower: {vision_tower}')
2024-04-01 09:14:38 | ERROR | stderr | ValueError: Unknown vision tower: ../weights/LLaVA-7b-pretrain-projector-v0-CC3M-595K-original_caption.bin
2024-04-01 09:15:50 | WARNING | transformers.models.llama.tokenization_llama | You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
2024-04-01 09:15:50 | WARNING | transformers.models.clip.configuration_clip | You are using a model of type llava to instantiate a model of type clip_vision_model. This is not supported for all configurations of models and can yield errors.
2024-04-01 09:15:50 | WARNING | transformers.models.clip.configuration_clip | You are using a model of type llava to instantiate a model of type clip_vision_model. This is not supported for all configurations of models and can yield errors.
2024-04-01 09:15:51 | ERROR | stderr | Loading checkpoint shards:   0%|                                                               | 0/2 [00:00<?, ?it/s]
2024-04-01 09:17:14 | ERROR | stderr | Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 1/2 [01:23<01:23, 83.53s/it]
2024-04-01 09:17:42 | ERROR | stderr | Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:51<00:00, 50.85s/it]
2024-04-01 09:17:42 | ERROR | stderr | Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:51<00:00, 55.76s/it]
2024-04-01 09:17:42 | ERROR | stderr | 
2024-04-01 09:17:42 | WARNING | transformers.modeling_utils | Some weights of the model checkpoint at ../weights/llava_plus_v0_7b were not used when initializing LlavaLlamaForCausalLM: ['model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.class_embedding', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias']
- This IS expected if you are initializing LlavaLlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LlavaLlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2024-04-01 09:17:42 | WARNING | transformers.modeling_utils | Some weights of the model checkpoint at ../weights/llava_plus_v0_7b were not used when initializing LlavaLlamaForCausalLM: ['model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.class_embedding', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias']
- This IS expected if you are initializing LlavaLlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LlavaLlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2024-04-01 09:17:43 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 09:17:43 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/llava/model_worker.py", line 271, in <module>
2024-04-01 09:17:43 | ERROR | stderr |     worker = ModelWorker(args.controller_address,
2024-04-01 09:17:43 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/llava/model_worker.py", line 61, in __init__
2024-04-01 09:17:43 | ERROR | stderr |     self.tokenizer, self.model, self.image_processor, self.context_len = load_pretrained_model(
2024-04-01 09:17:43 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/llava/model/builder.py", line 142, in load_pretrained_model
2024-04-01 09:17:43 | ERROR | stderr |     vision_tower.load_model()
2024-04-01 09:17:43 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/llava/model/multimodal_encoder/clip_encoder.py", line 23, in load_model
2024-04-01 09:17:43 | ERROR | stderr |     self.image_processor = CLIPImageProcessor.from_pretrained(self.vision_tower_name)
2024-04-01 09:17:43 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/transformers/image_processing_utils.py", line 195, in from_pretrained
2024-04-01 09:17:43 | ERROR | stderr |     image_processor_dict, kwargs = cls.get_image_processor_dict(pretrained_model_name_or_path, **kwargs)
2024-04-01 09:17:43 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/transformers/image_processing_utils.py", line 299, in get_image_processor_dict
2024-04-01 09:17:43 | ERROR | stderr |     resolved_image_processor_file = cached_file(
2024-04-01 09:17:43 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/transformers/utils/hub.py", line 388, in cached_file
2024-04-01 09:17:43 | ERROR | stderr |     raise EnvironmentError(
2024-04-01 09:17:43 | ERROR | stderr | OSError: ../weights/projector does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co/../weights/projector/main' for available files.
2024-04-01 09:25:23 | WARNING | transformers.models.llama.tokenization_llama | You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
2024-04-01 09:25:23 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 09:25:23 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/llava/model_worker.py", line 271, in <module>
2024-04-01 09:25:23 | ERROR | stderr |     worker = ModelWorker(args.controller_address,
2024-04-01 09:25:23 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/llava/model_worker.py", line 61, in __init__
2024-04-01 09:25:23 | ERROR | stderr |     self.tokenizer, self.model, self.image_processor, self.context_len = load_pretrained_model(
2024-04-01 09:25:23 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/llava/model/builder.py", line 106, in load_pretrained_model
2024-04-01 09:25:23 | ERROR | stderr |     model = LlavaLlamaForCausalLM.from_pretrained(model_path, low_cpu_mem_usage=True, **kwargs)
2024-04-01 09:25:23 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/transformers/modeling_utils.py", line 2700, in from_pretrained
2024-04-01 09:25:23 | ERROR | stderr |     model = cls(config, *model_args, **model_kwargs)
2024-04-01 09:25:23 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/llava/model/language_model/llava_llama.py", line 45, in __init__
2024-04-01 09:25:23 | ERROR | stderr |     self.model = LlavaLlamaModel(config)
2024-04-01 09:25:23 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/llava/model/language_model/llava_llama.py", line 37, in __init__
2024-04-01 09:25:23 | ERROR | stderr |     super(LlavaLlamaModel, self).__init__(config)
2024-04-01 09:25:23 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/llava/model/llava_arch.py", line 33, in __init__
2024-04-01 09:25:23 | ERROR | stderr |     self.vision_tower = build_vision_tower(config, delay_load=True)
2024-04-01 09:25:23 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/llava/model/multimodal_encoder/builder.py", line 11, in build_vision_tower
2024-04-01 09:25:23 | ERROR | stderr |     raise ValueError(f'Unknown vision tower: {vision_tower}')
2024-04-01 09:25:23 | ERROR | stderr | ValueError: Unknown vision tower: ../weights/mm_projector.bin
2024-04-01 09:27:42 | WARNING | transformers.models.llama.tokenization_llama | You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
2024-04-01 09:27:42 | ERROR | stderr | config.json:   0%|                                                                       | 0.00/4.52k [00:00<?, ?B/s]
2024-04-01 09:27:42 | ERROR | stderr | config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.52k/4.52k [00:00<00:00, 788kB/s]
2024-04-01 09:27:42 | ERROR | stderr | 
2024-04-01 09:27:44 | ERROR | stderr | Loading checkpoint shards:   0%|                                                               | 0/2 [00:00<?, ?it/s]
2024-04-01 09:29:05 | ERROR | stderr | Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 1/2 [01:21<01:21, 81.30s/it]
2024-04-01 09:29:17 | ERROR | stderr | Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 1/2 [01:33<01:33, 93.22s/it]
2024-04-01 09:29:17 | ERROR | stderr | 
2024-04-01 09:29:17 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 09:29:17 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/llava/model_worker.py", line 271, in <module>
2024-04-01 09:29:17 | ERROR | stderr |     worker = ModelWorker(args.controller_address,
2024-04-01 09:29:17 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/llava/model_worker.py", line 61, in __init__
2024-04-01 09:29:17 | ERROR | stderr |     self.tokenizer, self.model, self.image_processor, self.context_len = load_pretrained_model(
2024-04-01 09:29:17 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/llava/model/builder.py", line 106, in load_pretrained_model
2024-04-01 09:29:17 | ERROR | stderr |     model = LlavaLlamaForCausalLM.from_pretrained(model_path, low_cpu_mem_usage=True, **kwargs)
2024-04-01 09:29:17 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/transformers/modeling_utils.py", line 2903, in from_pretrained
2024-04-01 09:29:17 | ERROR | stderr |     ) = cls._load_pretrained_model(
2024-04-01 09:29:17 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3246, in _load_pretrained_model
2024-04-01 09:29:17 | ERROR | stderr |     state_dict = load_state_dict(shard_file)
2024-04-01 09:29:17 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/transformers/modeling_utils.py", line 460, in load_state_dict
2024-04-01 09:29:17 | ERROR | stderr |     return torch.load(checkpoint_file, map_location="cpu")
2024-04-01 09:29:17 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/torch/serialization.py", line 809, in load
2024-04-01 09:29:17 | ERROR | stderr |     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
2024-04-01 09:29:17 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/torch/serialization.py", line 1172, in _load
2024-04-01 09:29:17 | ERROR | stderr |     result = unpickler.load()
2024-04-01 09:29:17 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/torch/serialization.py", line 1142, in persistent_load
2024-04-01 09:29:17 | ERROR | stderr |     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
2024-04-01 09:29:17 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/torch/serialization.py", line 1112, in load_tensor
2024-04-01 09:29:17 | ERROR | stderr |     storage = zip_file.get_storage_from_record(name, numel, torch.UntypedStorage)._typed_storage()._untyped_storage
2024-04-01 09:29:17 | ERROR | stderr | KeyboardInterrupt
2024-04-01 09:30:20 | WARNING | transformers.models.llama.tokenization_llama | You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
2024-04-01 09:30:22 | ERROR | stderr | Loading checkpoint shards:   0%|                                                               | 0/2 [00:00<?, ?it/s]
2024-04-01 09:31:36 | ERROR | stderr | Loading checkpoint shards:   0%|                                                               | 0/2 [01:13<?, ?it/s]
2024-04-01 09:31:36 | ERROR | stderr | 
2024-04-01 09:31:36 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 09:31:36 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/llava/model_worker.py", line 271, in <module>
2024-04-01 09:31:36 | ERROR | stderr |     worker = ModelWorker(args.controller_address,
2024-04-01 09:31:36 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/llava/model_worker.py", line 61, in __init__
2024-04-01 09:31:36 | ERROR | stderr |     self.tokenizer, self.model, self.image_processor, self.context_len = load_pretrained_model(
2024-04-01 09:31:36 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/llava/model/builder.py", line 106, in load_pretrained_model
2024-04-01 09:31:36 | ERROR | stderr |     model = LlavaLlamaForCausalLM.from_pretrained(model_path, low_cpu_mem_usage=True, **kwargs)
2024-04-01 09:31:36 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/transformers/modeling_utils.py", line 2903, in from_pretrained
2024-04-01 09:31:36 | ERROR | stderr |     ) = cls._load_pretrained_model(
2024-04-01 09:31:36 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3260, in _load_pretrained_model
2024-04-01 09:31:36 | ERROR | stderr |     new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
2024-04-01 09:31:36 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/transformers/modeling_utils.py", line 725, in _load_state_dict_into_meta_model
2024-04-01 09:31:36 | ERROR | stderr |     set_module_quantized_tensor_to_device(
2024-04-01 09:31:36 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/transformers/utils/bitsandbytes.py", line 99, in set_module_quantized_tensor_to_device
2024-04-01 09:31:36 | ERROR | stderr |     new_value = bnb.nn.Params4bit(new_value, requires_grad=False, **kwargs).to(device)
2024-04-01 09:31:36 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/bitsandbytes/nn/modules.py", line 179, in to
2024-04-01 09:31:36 | ERROR | stderr |     return self.cuda(device)
2024-04-01 09:31:36 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/bitsandbytes/nn/modules.py", line 156, in cuda
2024-04-01 09:31:36 | ERROR | stderr |     w = self.data.contiguous().half().cuda(device)
2024-04-01 09:31:36 | ERROR | stderr | KeyboardInterrupt
2024-04-01 09:33:54 | INFO | stdout | --------self.model_name:  llava_plus_v0_7b
2024-04-01 09:33:54 | WARNING | transformers.models.llama.tokenization_llama | You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
2024-04-01 09:33:56 | ERROR | stderr | Loading checkpoint shards:   0%|                                                               | 0/2 [00:00<?, ?it/s]
2024-04-01 09:33:58 | ERROR | stderr | Loading checkpoint shards:   0%|                                                               | 0/2 [00:02<?, ?it/s]
2024-04-01 09:33:58 | ERROR | stderr | 
2024-04-01 09:33:58 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 09:33:58 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/llava/model_worker.py", line 272, in <module>
2024-04-01 09:33:58 | ERROR | stderr |     worker = ModelWorker(args.controller_address,
2024-04-01 09:33:58 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/llava/model_worker.py", line 62, in __init__
2024-04-01 09:33:58 | ERROR | stderr |     self.tokenizer, self.model, self.image_processor, self.context_len = load_pretrained_model(
2024-04-01 09:33:58 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/llava/model/builder.py", line 106, in load_pretrained_model
2024-04-01 09:33:58 | ERROR | stderr |     model = LlavaLlamaForCausalLM.from_pretrained(model_path, low_cpu_mem_usage=True, **kwargs)
2024-04-01 09:33:58 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/transformers/modeling_utils.py", line 2903, in from_pretrained
2024-04-01 09:33:58 | ERROR | stderr |     ) = cls._load_pretrained_model(
2024-04-01 09:33:58 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3246, in _load_pretrained_model
2024-04-01 09:33:58 | ERROR | stderr |     state_dict = load_state_dict(shard_file)
2024-04-01 09:33:58 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/transformers/modeling_utils.py", line 460, in load_state_dict
2024-04-01 09:33:58 | ERROR | stderr |     return torch.load(checkpoint_file, map_location="cpu")
2024-04-01 09:33:58 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/torch/serialization.py", line 809, in load
2024-04-01 09:33:58 | ERROR | stderr |     return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
2024-04-01 09:33:58 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/torch/serialization.py", line 1172, in _load
2024-04-01 09:33:58 | ERROR | stderr |     result = unpickler.load()
2024-04-01 09:33:58 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/torch/serialization.py", line 1142, in persistent_load
2024-04-01 09:33:58 | ERROR | stderr |     typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
2024-04-01 09:33:58 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/torch/serialization.py", line 1112, in load_tensor
2024-04-01 09:33:58 | ERROR | stderr |     storage = zip_file.get_storage_from_record(name, numel, torch.UntypedStorage)._typed_storage()._untyped_storage
2024-04-01 09:33:58 | ERROR | stderr | KeyboardInterrupt
2024-04-01 09:36:04 | INFO | stdout | --------self.model_name:  llava_plus_v0_7b
2024-04-01 09:36:04 | INFO | stdout | Loading LLaVA from base model...
2024-04-01 09:36:04 | WARNING | transformers.models.llama.tokenization_llama | You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
2024-04-01 09:36:06 | ERROR | stderr | Loading checkpoint shards:   0%|                                                               | 0/2 [00:00<?, ?it/s]
2024-04-01 09:37:24 | ERROR | stderr | Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 1/2 [01:18<01:18, 78.45s/it]
2024-04-01 09:37:56 | ERROR | stderr | Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:50<00:00, 51.22s/it]
2024-04-01 09:37:56 | ERROR | stderr | Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:50<00:00, 55.31s/it]
2024-04-01 09:37:56 | ERROR | stderr | 
2024-04-01 09:37:56 | WARNING | transformers.modeling_utils | Some weights of the model checkpoint at ../weights/llava_plus_v0_7b were not used when initializing LlavaLlamaForCausalLM: ['model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.class_embedding', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight']
- This IS expected if you are initializing LlavaLlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LlavaLlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2024-04-01 09:37:56 | WARNING | transformers.modeling_utils | Some weights of the model checkpoint at ../weights/llava_plus_v0_7b were not used when initializing LlavaLlamaForCausalLM: ['model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.class_embedding', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight']
- This IS expected if you are initializing LlavaLlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LlavaLlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2024-04-01 09:37:57 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 09:37:57 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/llava/model_worker.py", line 272, in <module>
2024-04-01 09:37:57 | ERROR | stderr |     worker = ModelWorker(args.controller_address,
2024-04-01 09:37:57 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/llava/model_worker.py", line 62, in __init__
2024-04-01 09:37:57 | ERROR | stderr |     self.tokenizer, self.model, self.image_processor, self.context_len = load_pretrained_model(
2024-04-01 09:37:57 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/llava/model/builder.py", line 99, in load_pretrained_model
2024-04-01 09:37:57 | ERROR | stderr |     model.load_state_dict(mm_projector_weights, strict=False)
2024-04-01 09:37:57 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 2041, in load_state_dict
2024-04-01 09:37:57 | ERROR | stderr |     raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
2024-04-01 09:37:57 | ERROR | stderr | RuntimeError: Error(s) in loading state_dict for LlavaLlamaForCausalLM:
2024-04-01 09:37:57 | ERROR | stderr | 	size mismatch for model.embed_tokens.weight: copying a param with shape torch.Size([2, 4096]) from checkpoint, the shape in current model is torch.Size([32001, 4096]).
2024-04-01 09:37:57 | ERROR | stderr | 	size mismatch for model.mm_projector.weight: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([2097152, 1]).
2024-04-01 09:45:41 | INFO | stdout | --------self.model_name:  llava_plus_v0_7b
2024-04-01 09:45:41 | WARNING | transformers.models.llama.tokenization_llama | You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565
2024-04-01 09:45:42 | ERROR | stderr | Loading checkpoint shards:   0%|                                                               | 0/2 [00:00<?, ?it/s]
2024-04-01 09:47:01 | ERROR | stderr | Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 1/2 [01:18<01:18, 78.58s/it]
2024-04-01 09:47:29 | ERROR | stderr | Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:46<00:00, 48.80s/it]
2024-04-01 09:47:29 | ERROR | stderr | Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:46<00:00, 53.27s/it]
2024-04-01 09:47:29 | ERROR | stderr | 
2024-04-01 09:47:29 | WARNING | transformers.modeling_utils | Some weights of the model checkpoint at ../weights/llava_plus_v0_7b were not used when initializing LlavaLlamaForCausalLM: ['model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.class_embedding', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight', 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias']
- This IS expected if you are initializing LlavaLlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LlavaLlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2024-04-01 09:47:29 | WARNING | transformers.modeling_utils | Some weights of the model checkpoint at ../weights/llava_plus_v0_7b were not used when initializing LlavaLlamaForCausalLM: ['model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.class_embedding', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight', 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias']
- This IS expected if you are initializing LlavaLlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LlavaLlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2024-04-01 09:47:30 | ERROR | stderr | preprocessor_config.json:   0%|                                                            | 0.00/316 [00:00<?, ?B/s]
2024-04-01 09:47:30 | ERROR | stderr | preprocessor_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 316/316 [00:00<00:00, 94.8kB/s]
2024-04-01 09:47:30 | ERROR | stderr | 
2024-04-01 09:47:31 | ERROR | stderr | model.safetensors:   0%|                                                                 | 0.00/1.71G [00:00<?, ?B/s]
2024-04-01 09:47:32 | ERROR | stderr | model.safetensors:   1%|â–Ž                                                       | 10.5M/1.71G [00:00<02:26, 11.6MB/s]
2024-04-01 09:47:33 | ERROR | stderr | model.safetensors:   1%|â–‹                                                       | 21.0M/1.71G [00:01<02:26, 11.6MB/s]
2024-04-01 09:47:34 | ERROR | stderr | model.safetensors:   2%|â–ˆ                                                       | 31.5M/1.71G [00:02<02:25, 11.5MB/s]
2024-04-01 09:47:34 | ERROR | stderr | model.safetensors:   2%|â–ˆâ–Ž                                                      | 41.9M/1.71G [00:03<02:24, 11.6MB/s]
2024-04-01 09:47:35 | ERROR | stderr | model.safetensors:   3%|â–ˆâ–‹                                                      | 52.4M/1.71G [00:04<02:23, 11.5MB/s]
2024-04-01 09:47:36 | ERROR | stderr | model.safetensors:   4%|â–ˆâ–ˆ                                                      | 62.9M/1.71G [00:05<02:24, 11.4MB/s]
2024-04-01 09:47:37 | ERROR | stderr | model.safetensors:   4%|â–ˆâ–ˆâ–                                                     | 73.4M/1.71G [00:06<02:23, 11.4MB/s]
2024-04-01 09:47:38 | ERROR | stderr | model.safetensors:   5%|â–ˆâ–ˆâ–‹                                                     | 83.9M/1.71G [00:07<02:26, 11.1MB/s]
2024-04-01 09:47:39 | ERROR | stderr | model.safetensors:   6%|â–ˆâ–ˆâ–ˆ                                                     | 94.4M/1.71G [00:08<02:24, 11.2MB/s]
2024-04-01 09:47:40 | ERROR | stderr | model.safetensors:   6%|â–ˆâ–ˆâ–ˆâ–                                                     | 105M/1.71G [00:09<02:22, 11.3MB/s]
2024-04-01 09:47:41 | ERROR | stderr | model.safetensors:   7%|â–ˆâ–ˆâ–ˆâ–Š                                                     | 115M/1.71G [00:10<02:20, 11.3MB/s]
2024-04-01 09:47:42 | ERROR | stderr | model.safetensors:   7%|â–ˆâ–ˆâ–ˆâ–ˆâ–                                                    | 126M/1.71G [00:11<02:19, 11.4MB/s]
2024-04-01 09:47:43 | ERROR | stderr | model.safetensors:   8%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                    | 136M/1.71G [00:11<02:18, 11.3MB/s]
2024-04-01 09:47:44 | ERROR | stderr | model.safetensors:   9%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                    | 147M/1.71G [00:12<02:17, 11.4MB/s]
2024-04-01 09:47:45 | ERROR | stderr | model.safetensors:   9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                   | 157M/1.71G [00:13<02:15, 11.5MB/s]
2024-04-01 09:47:46 | ERROR | stderr | model.safetensors:  10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                   | 168M/1.71G [00:14<02:14, 11.4MB/s]
2024-04-01 09:47:46 | ERROR | stderr | model.safetensors:  10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                   | 178M/1.71G [00:15<02:13, 11.5MB/s]
2024-04-01 09:47:47 | ERROR | stderr | model.safetensors:  11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                  | 189M/1.71G [00:16<02:14, 11.3MB/s]
2024-04-01 09:47:48 | ERROR | stderr | model.safetensors:  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                  | 199M/1.71G [00:17<02:13, 11.3MB/s]
2024-04-01 09:47:49 | ERROR | stderr | model.safetensors:  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                  | 210M/1.71G [00:18<02:12, 11.4MB/s]
2024-04-01 09:47:50 | ERROR | stderr | model.safetensors:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                 | 220M/1.71G [00:19<02:10, 11.4MB/s]
2024-04-01 09:47:51 | ERROR | stderr | model.safetensors:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                 | 231M/1.71G [00:20<02:17, 10.8MB/s]
2024-04-01 09:47:52 | ERROR | stderr | model.safetensors:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                 | 241M/1.71G [00:21<02:14, 11.0MB/s]
2024-04-01 09:47:53 | ERROR | stderr | model.safetensors:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                | 252M/1.71G [00:22<02:11, 11.1MB/s]
2024-04-01 09:47:54 | ERROR | stderr | model.safetensors:  15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                | 262M/1.71G [00:23<02:08, 11.2MB/s]
2024-04-01 09:47:55 | ERROR | stderr | model.safetensors:  16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                | 273M/1.71G [00:24<02:07, 11.2MB/s]
2024-04-01 09:47:56 | ERROR | stderr | model.safetensors:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                               | 283M/1.71G [00:25<02:05, 11.4MB/s]
2024-04-01 09:47:57 | ERROR | stderr | model.safetensors:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                               | 294M/1.71G [00:25<02:04, 11.4MB/s]
2024-04-01 09:47:58 | ERROR | stderr | model.safetensors:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                              | 304M/1.71G [00:26<02:03, 11.3MB/s]
2024-04-01 09:47:59 | ERROR | stderr | model.safetensors:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                              | 315M/1.71G [00:27<02:02, 11.4MB/s]
2024-04-01 09:48:00 | ERROR | stderr | model.safetensors:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                              | 325M/1.71G [00:28<02:01, 11.4MB/s]
2024-04-01 09:48:00 | ERROR | stderr | model.safetensors:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                             | 336M/1.71G [00:29<01:59, 11.5MB/s]
2024-04-01 09:48:02 | ERROR | stderr | model.safetensors:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                             | 346M/1.71G [00:30<02:06, 10.8MB/s]
2024-04-01 09:48:03 | ERROR | stderr | model.safetensors:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                             | 357M/1.71G [00:31<02:04, 10.9MB/s]
2024-04-01 09:48:03 | ERROR | stderr | model.safetensors:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                            | 367M/1.71G [00:32<02:01, 11.0MB/s]
2024-04-01 09:48:04 | ERROR | stderr | model.safetensors:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                            | 377M/1.71G [00:33<01:59, 11.2MB/s]
2024-04-01 09:48:05 | ERROR | stderr | model.safetensors:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                            | 388M/1.71G [00:34<01:57, 11.2MB/s]
2024-04-01 09:48:06 | ERROR | stderr | model.safetensors:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                           | 398M/1.71G [00:35<01:55, 11.3MB/s]
2024-04-01 09:48:11 | ERROR | stderr | model.safetensors:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                           | 409M/1.71G [00:40<04:20, 4.99MB/s]
2024-04-01 09:48:14 | ERROR | stderr | model.safetensors:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                           | 419M/1.71G [00:42<04:33, 4.72MB/s]
2024-04-01 09:48:14 | ERROR | stderr | model.safetensors:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                          | 430M/1.71G [00:43<03:43, 5.73MB/s]
2024-04-01 09:48:15 | ERROR | stderr | model.safetensors:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                          | 440M/1.71G [00:44<03:08, 6.74MB/s]
2024-04-01 09:48:16 | ERROR | stderr | model.safetensors:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                          | 451M/1.71G [00:45<02:43, 7.70MB/s]
2024-04-01 09:48:17 | ERROR | stderr | model.safetensors:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                         | 461M/1.71G [00:46<02:28, 8.43MB/s]
2024-04-01 09:48:18 | ERROR | stderr | model.safetensors:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                         | 472M/1.71G [00:47<02:15, 9.16MB/s]
2024-04-01 09:48:19 | ERROR | stderr | model.safetensors:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                         | 482M/1.71G [00:48<02:06, 9.72MB/s]
2024-04-01 09:48:20 | ERROR | stderr | model.safetensors:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                        | 493M/1.71G [00:49<01:59, 10.2MB/s]
2024-04-01 09:48:21 | ERROR | stderr | model.safetensors:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                        | 503M/1.71G [00:50<01:54, 10.5MB/s]
2024-04-01 09:48:22 | ERROR | stderr | model.safetensors:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                        | 514M/1.71G [00:50<01:50, 10.8MB/s]
2024-04-01 09:48:23 | ERROR | stderr | model.safetensors:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                       | 524M/1.71G [00:52<01:53, 10.4MB/s]
2024-04-01 09:48:24 | ERROR | stderr | model.safetensors:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                       | 535M/1.71G [00:52<01:49, 10.7MB/s]
2024-04-01 09:48:25 | ERROR | stderr | model.safetensors:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                      | 545M/1.71G [00:53<01:46, 11.0MB/s]
2024-04-01 09:48:26 | ERROR | stderr | model.safetensors:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                      | 556M/1.71G [00:54<01:44, 11.1MB/s]
2024-04-01 09:48:27 | ERROR | stderr | model.safetensors:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                      | 566M/1.71G [00:55<01:45, 10.9MB/s]
2024-04-01 09:48:28 | ERROR | stderr | model.safetensors:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                     | 577M/1.71G [00:56<01:42, 11.0MB/s]
2024-04-01 09:48:28 | ERROR | stderr | model.safetensors:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                     | 587M/1.71G [00:57<01:40, 11.1MB/s]
2024-04-01 09:48:29 | ERROR | stderr | model.safetensors:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                     | 598M/1.71G [00:58<01:39, 11.2MB/s]
2024-04-01 09:48:30 | ERROR | stderr | model.safetensors:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                    | 608M/1.71G [00:59<01:37, 11.3MB/s]
2024-04-01 09:48:31 | ERROR | stderr | model.safetensors:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                    | 619M/1.71G [01:00<01:36, 11.3MB/s]
2024-04-01 09:48:32 | ERROR | stderr | model.safetensors:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                    | 629M/1.71G [01:01<01:36, 11.2MB/s]
2024-04-01 09:48:33 | ERROR | stderr | model.safetensors:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                   | 640M/1.71G [01:02<01:40, 10.6MB/s]
2024-04-01 09:48:34 | ERROR | stderr | model.safetensors:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                   | 650M/1.71G [01:03<01:37, 10.9MB/s]
2024-04-01 09:48:35 | ERROR | stderr | model.safetensors:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                   | 661M/1.71G [01:04<01:34, 11.1MB/s]
2024-04-01 09:48:36 | ERROR | stderr | model.safetensors:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                  | 671M/1.71G [01:05<01:32, 11.2MB/s]
2024-04-01 09:48:37 | ERROR | stderr | model.safetensors:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                  | 682M/1.71G [01:06<01:31, 11.3MB/s]
2024-04-01 09:48:38 | ERROR | stderr | model.safetensors:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                  | 692M/1.71G [01:06<01:29, 11.3MB/s]
2024-04-01 09:48:39 | ERROR | stderr | model.safetensors:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                 | 703M/1.71G [01:07<01:28, 11.3MB/s]
2024-04-01 09:48:40 | ERROR | stderr | model.safetensors:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                 | 713M/1.71G [01:08<01:27, 11.4MB/s]
2024-04-01 09:48:41 | ERROR | stderr | model.safetensors:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                 | 724M/1.71G [01:09<01:26, 11.4MB/s]
2024-04-01 09:48:41 | ERROR | stderr | model.safetensors:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                | 734M/1.71G [01:10<01:25, 11.4MB/s]
2024-04-01 09:48:42 | ERROR | stderr | model.safetensors:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                | 744M/1.71G [01:11<01:25, 11.3MB/s]
2024-04-01 09:48:44 | ERROR | stderr | model.safetensors:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                               | 755M/1.71G [01:12<01:28, 10.7MB/s]
2024-04-01 09:48:44 | ERROR | stderr | model.safetensors:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                               | 765M/1.71G [01:13<01:26, 11.0MB/s]
2024-04-01 09:48:45 | ERROR | stderr | model.safetensors:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                               | 776M/1.71G [01:14<01:24, 11.1MB/s]
2024-04-01 09:48:46 | ERROR | stderr | model.safetensors:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                              | 786M/1.71G [01:15<01:22, 11.2MB/s]
2024-04-01 09:48:47 | ERROR | stderr | model.safetensors:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                              | 797M/1.71G [01:16<01:20, 11.3MB/s]
2024-04-01 09:48:48 | ERROR | stderr | model.safetensors:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                              | 807M/1.71G [01:17<01:19, 11.4MB/s]
2024-04-01 09:48:49 | ERROR | stderr | model.safetensors:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                             | 818M/1.71G [01:18<01:18, 11.4MB/s]
2024-04-01 09:48:50 | ERROR | stderr | model.safetensors:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                             | 828M/1.71G [01:19<01:17, 11.5MB/s]
2024-04-01 09:48:51 | ERROR | stderr | model.safetensors:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                             | 839M/1.71G [01:19<01:16, 11.4MB/s]
2024-04-01 09:48:52 | ERROR | stderr | model.safetensors:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                            | 849M/1.71G [01:20<01:15, 11.5MB/s]
2024-04-01 09:48:53 | ERROR | stderr | model.safetensors:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                            | 860M/1.71G [01:21<01:14, 11.5MB/s]
2024-04-01 09:48:54 | ERROR | stderr | model.safetensors:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                            | 870M/1.71G [01:22<01:17, 10.8MB/s]
2024-04-01 09:48:55 | ERROR | stderr | model.safetensors:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                           | 881M/1.71G [01:23<01:15, 11.0MB/s]
2024-04-01 09:48:56 | ERROR | stderr | model.safetensors:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                           | 891M/1.71G [01:24<01:13, 11.1MB/s]
2024-04-01 09:48:57 | ERROR | stderr | model.safetensors:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           | 902M/1.71G [01:25<01:13, 11.0MB/s]
2024-04-01 09:48:58 | ERROR | stderr | model.safetensors:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 912M/1.71G [01:26<01:12, 10.9MB/s]
2024-04-01 09:48:58 | ERROR | stderr | model.safetensors:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 923M/1.71G [01:27<01:11, 11.0MB/s]
2024-04-01 09:48:59 | ERROR | stderr | model.safetensors:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 933M/1.71G [01:28<01:09, 11.1MB/s]
2024-04-01 09:49:00 | ERROR | stderr | model.safetensors:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 944M/1.71G [01:29<01:08, 11.3MB/s]
2024-04-01 09:49:01 | ERROR | stderr | model.safetensors:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                         | 954M/1.71G [01:30<01:06, 11.3MB/s]
2024-04-01 09:49:02 | ERROR | stderr | model.safetensors:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 965M/1.71G [01:31<01:05, 11.4MB/s]
2024-04-01 09:49:03 | ERROR | stderr | model.safetensors:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 975M/1.71G [01:32<01:04, 11.3MB/s]
2024-04-01 09:49:04 | ERROR | stderr | model.safetensors:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 986M/1.71G [01:33<01:07, 10.8MB/s]
2024-04-01 09:49:05 | ERROR | stderr | model.safetensors:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 996M/1.71G [01:34<01:05, 11.0MB/s]
2024-04-01 09:49:06 | ERROR | stderr | model.safetensors:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                       | 1.01G/1.71G [01:35<01:03, 11.1MB/s]
2024-04-01 09:49:07 | ERROR | stderr | model.safetensors:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                      | 1.02G/1.71G [01:36<01:01, 11.2MB/s]
2024-04-01 09:49:08 | ERROR | stderr | model.safetensors:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 1.03G/1.71G [01:36<01:00, 11.3MB/s]
2024-04-01 09:49:09 | ERROR | stderr | model.safetensors:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                      | 1.04G/1.71G [01:37<00:59, 11.3MB/s]
2024-04-01 09:49:10 | ERROR | stderr | model.safetensors:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                     | 1.05G/1.71G [01:38<00:57, 11.4MB/s]
2024-04-01 09:49:11 | ERROR | stderr | model.safetensors:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                     | 1.06G/1.71G [01:39<00:57, 11.4MB/s]
2024-04-01 09:49:11 | ERROR | stderr | model.safetensors:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     | 1.07G/1.71G [01:40<00:56, 11.4MB/s]
2024-04-01 09:49:12 | ERROR | stderr | model.safetensors:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 1.08G/1.71G [01:41<00:54, 11.5MB/s]
2024-04-01 09:49:13 | ERROR | stderr | model.safetensors:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                    | 1.09G/1.71G [01:42<00:54, 11.5MB/s]
2024-04-01 09:49:14 | ERROR | stderr | model.safetensors:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 1.10G/1.71G [01:43<00:57, 10.7MB/s]
2024-04-01 09:49:15 | ERROR | stderr | model.safetensors:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                   | 1.11G/1.71G [01:44<00:56, 10.5MB/s]
2024-04-01 09:49:16 | ERROR | stderr | model.safetensors:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                   | 1.12G/1.71G [01:45<00:54, 10.7MB/s]
2024-04-01 09:49:17 | ERROR | stderr | model.safetensors:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 1.13G/1.71G [01:46<00:53, 10.8MB/s]
2024-04-01 09:49:18 | ERROR | stderr | model.safetensors:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 1.14G/1.71G [01:47<00:52, 10.8MB/s]
2024-04-01 09:49:19 | ERROR | stderr | model.safetensors:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                  | 1.15G/1.71G [01:48<00:50, 10.9MB/s]
2024-04-01 09:49:20 | ERROR | stderr | model.safetensors:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  | 1.16G/1.71G [01:49<00:49, 11.1MB/s]
2024-04-01 09:49:21 | ERROR | stderr | model.safetensors:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 1.17G/1.71G [01:50<00:47, 11.2MB/s]
2024-04-01 09:49:22 | ERROR | stderr | model.safetensors:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                 | 1.18G/1.71G [01:51<00:46, 11.3MB/s]
2024-04-01 09:49:23 | ERROR | stderr | model.safetensors:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 1.20G/1.71G [01:52<00:45, 11.3MB/s]
2024-04-01 09:49:24 | ERROR | stderr | model.safetensors:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 1.21G/1.71G [01:52<00:44, 11.4MB/s]
2024-04-01 09:49:25 | ERROR | stderr | model.safetensors:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                | 1.22G/1.71G [01:53<00:43, 11.4MB/s]
2024-04-01 09:49:26 | ERROR | stderr | model.safetensors:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–               | 1.23G/1.71G [01:54<00:42, 11.4MB/s]
2024-04-01 09:49:27 | ERROR | stderr | model.safetensors:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ               | 1.24G/1.71G [01:55<00:41, 11.5MB/s]
2024-04-01 09:49:27 | ERROR | stderr | model.safetensors:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š               | 1.25G/1.71G [01:56<00:40, 11.4MB/s]
2024-04-01 09:49:28 | ERROR | stderr | model.safetensors:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 1.26G/1.71G [01:57<00:39, 11.5MB/s]
2024-04-01 09:49:29 | ERROR | stderr | model.safetensors:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 1.27G/1.71G [01:58<00:38, 11.5MB/s]
2024-04-01 09:49:30 | ERROR | stderr | model.safetensors:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰              | 1.28G/1.71G [01:59<00:38, 11.2MB/s]
2024-04-01 09:49:31 | ERROR | stderr | model.safetensors:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 1.29G/1.71G [02:00<00:38, 11.0MB/s]
2024-04-01 09:49:32 | ERROR | stderr | model.safetensors:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 1.30G/1.71G [02:01<00:36, 11.1MB/s]
2024-04-01 09:49:33 | ERROR | stderr | model.safetensors:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 1.31G/1.71G [02:02<00:35, 11.2MB/s]
2024-04-01 09:49:34 | ERROR | stderr | model.safetensors:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž            | 1.32G/1.71G [02:03<00:34, 11.3MB/s]
2024-04-01 09:49:35 | ERROR | stderr | model.safetensors:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 1.33G/1.71G [02:04<00:33, 11.3MB/s]
2024-04-01 09:49:36 | ERROR | stderr | model.safetensors:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰            | 1.34G/1.71G [02:04<00:32, 11.4MB/s]
2024-04-01 09:49:37 | ERROR | stderr | model.safetensors:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž           | 1.35G/1.71G [02:05<00:31, 11.4MB/s]
2024-04-01 09:49:38 | ERROR | stderr | model.safetensors:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹           | 1.36G/1.71G [02:06<00:30, 11.4MB/s]
2024-04-01 09:49:39 | ERROR | stderr | model.safetensors:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰           | 1.37G/1.71G [02:07<00:29, 11.5MB/s]
2024-04-01 09:49:39 | ERROR | stderr | model.safetensors:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 1.38G/1.71G [02:08<00:28, 11.5MB/s]
2024-04-01 09:49:40 | ERROR | stderr | model.safetensors:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 1.39G/1.71G [02:09<00:27, 11.5MB/s]
2024-04-01 09:49:41 | ERROR | stderr | model.safetensors:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 1.41G/1.71G [02:10<00:26, 11.5MB/s]
2024-04-01 09:49:42 | ERROR | stderr | model.safetensors:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž         | 1.42G/1.71G [02:11<00:25, 11.5MB/s]
2024-04-01 09:49:43 | ERROR | stderr | model.safetensors:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 1.43G/1.71G [02:12<00:24, 11.4MB/s]
2024-04-01 09:49:44 | ERROR | stderr | model.safetensors:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 1.44G/1.71G [02:13<00:24, 11.3MB/s]
2024-04-01 09:49:45 | ERROR | stderr | model.safetensors:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž        | 1.45G/1.71G [02:14<00:23, 11.4MB/s]
2024-04-01 09:49:46 | ERROR | stderr | model.safetensors:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹        | 1.46G/1.71G [02:15<00:22, 11.4MB/s]
2024-04-01 09:49:47 | ERROR | stderr | model.safetensors:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 1.47G/1.71G [02:15<00:21, 11.4MB/s]
2024-04-01 09:49:48 | ERROR | stderr | model.safetensors:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 1.48G/1.71G [02:16<00:20, 11.4MB/s]
2024-04-01 09:49:49 | ERROR | stderr | model.safetensors:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹       | 1.49G/1.71G [02:18<00:20, 10.7MB/s]
2024-04-01 09:49:50 | ERROR | stderr | model.safetensors:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 1.50G/1.71G [02:18<00:19, 10.9MB/s]
2024-04-01 09:49:51 | ERROR | stderr | model.safetensors:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 1.51G/1.71G [02:19<00:18, 11.0MB/s]
2024-04-01 09:49:52 | ERROR | stderr | model.safetensors:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š      | 1.52G/1.71G [02:20<00:17, 11.1MB/s]
2024-04-01 09:49:53 | ERROR | stderr | model.safetensors:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 1.53G/1.71G [02:21<00:15, 11.2MB/s]
2024-04-01 09:49:53 | ERROR | stderr | model.safetensors:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 1.54G/1.71G [02:22<00:14, 11.3MB/s]
2024-04-01 09:49:54 | ERROR | stderr | model.safetensors:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1.55G/1.71G [02:23<00:13, 11.4MB/s]
2024-04-01 09:49:55 | ERROR | stderr | model.safetensors:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.56G/1.71G [02:24<00:13, 11.4MB/s]
2024-04-01 09:49:56 | ERROR | stderr | model.safetensors:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1.57G/1.71G [02:25<00:12, 11.4MB/s]
2024-04-01 09:49:57 | ERROR | stderr | model.safetensors:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1.58G/1.71G [02:26<00:11, 11.4MB/s]
2024-04-01 09:49:58 | ERROR | stderr | model.safetensors:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1.59G/1.71G [02:27<00:10, 11.5MB/s]
2024-04-01 09:49:59 | ERROR | stderr | model.safetensors:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1.60G/1.71G [02:28<00:09, 10.8MB/s]
2024-04-01 09:50:00 | ERROR | stderr | model.safetensors:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1.61G/1.71G [02:29<00:08, 11.0MB/s]
2024-04-01 09:50:01 | ERROR | stderr | model.safetensors:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1.63G/1.71G [02:30<00:07, 11.1MB/s]
2024-04-01 09:50:02 | ERROR | stderr | model.safetensors:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1.64G/1.71G [02:31<00:06, 11.3MB/s]
2024-04-01 09:50:03 | ERROR | stderr | model.safetensors:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1.65G/1.71G [02:31<00:05, 11.3MB/s]
2024-04-01 09:50:04 | ERROR | stderr | model.safetensors:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1.66G/1.71G [02:32<00:04, 11.4MB/s]
2024-04-01 09:50:05 | ERROR | stderr | model.safetensors:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1.67G/1.71G [02:33<00:03, 11.4MB/s]
2024-04-01 09:50:06 | ERROR | stderr | model.safetensors:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1.68G/1.71G [02:34<00:02, 11.4MB/s]
2024-04-01 09:50:06 | ERROR | stderr | model.safetensors:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1.69G/1.71G [02:35<00:01, 11.5MB/s]
2024-04-01 09:50:07 | ERROR | stderr | model.safetensors:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1.70G/1.71G [02:36<00:01, 11.5MB/s]
2024-04-01 09:50:08 | ERROR | stderr | model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1.71G/1.71G [02:37<00:00, 11.5MB/s]
2024-04-01 09:50:08 | ERROR | stderr | model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.71G/1.71G [02:37<00:00, 11.5MB/s]
2024-04-01 09:50:08 | ERROR | stderr | model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.71G/1.71G [02:37<00:00, 10.9MB/s]
2024-04-01 09:50:08 | ERROR | stderr | 
2024-04-01 09:50:10 | INFO | stdout | [32mINFO[0m:     127.0.0.1:44720 - "[1mPOST /register_worker HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 09:50:10 | ERROR | stderr | [32mINFO[0m:     Started server process [[36m24083[0m]
2024-04-01 09:50:10 | ERROR | stderr | [32mINFO[0m:     Waiting for application startup.
2024-04-01 09:50:10 | ERROR | stderr | [32mINFO[0m:     Application startup complete.
2024-04-01 09:50:10 | ERROR | stderr | [32mINFO[0m:     Uvicorn running on [1mhttp://0.0.0.0:21008[0m (Press CTRL+C to quit)
2024-04-01 09:50:40 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 09:50:40 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711939810.3903856)}
2024-04-01 09:50:40 | INFO | stdout | [32mINFO[0m:     127.0.0.1:42496 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 09:51:10 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 09:51:10 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711939840.4527907)}
2024-04-01 09:51:10 | INFO | stdout | [32mINFO[0m:     127.0.0.1:37632 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 09:51:40 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 09:51:40 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711939870.4904628)}
2024-04-01 09:51:40 | INFO | stdout | [32mINFO[0m:     127.0.0.1:39492 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 09:52:10 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 09:52:10 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711939900.5262733)}
2024-04-01 09:52:10 | INFO | stdout | [32mINFO[0m:     127.0.0.1:37874 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 09:52:40 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 09:52:40 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711939930.5604033)}
2024-04-01 09:52:40 | INFO | stdout | [32mINFO[0m:     127.0.0.1:51482 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 09:53:10 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 09:53:10 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711939960.594639)}
2024-04-01 09:53:10 | INFO | stdout | [32mINFO[0m:     127.0.0.1:55972 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 09:53:40 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 09:53:40 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711939990.6302226)}
2024-04-01 09:53:40 | INFO | stdout | [32mINFO[0m:     127.0.0.1:41480 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 09:54:10 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 09:54:10 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940020.6631668)}
2024-04-01 09:54:10 | INFO | stdout | [32mINFO[0m:     127.0.0.1:38158 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 09:54:40 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 09:54:40 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940050.7008066)}
2024-04-01 09:54:40 | INFO | stdout | [32mINFO[0m:     127.0.0.1:33768 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 09:55:10 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 09:55:10 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940080.738046)}
2024-04-01 09:55:10 | INFO | stdout | [32mINFO[0m:     127.0.0.1:48450 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 09:55:40 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 09:55:40 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940110.774554)}
2024-04-01 09:55:40 | INFO | stdout | [32mINFO[0m:     127.0.0.1:50074 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 09:56:10 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 09:56:10 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940140.810545)}
2024-04-01 09:56:10 | INFO | stdout | [32mINFO[0m:     127.0.0.1:58172 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 09:56:40 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 09:56:40 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940170.846509)}
2024-04-01 09:56:40 | INFO | stdout | [32mINFO[0m:     127.0.0.1:37494 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 09:57:10 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 09:57:10 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940200.8848147)}
2024-04-01 09:57:10 | INFO | stdout | [32mINFO[0m:     127.0.0.1:41926 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 09:57:40 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 09:57:40 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940230.9116)}
2024-04-01 09:57:40 | INFO | stdout | [32mINFO[0m:     127.0.0.1:38642 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 09:58:10 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 09:58:10 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940260.9436202)}
2024-04-01 09:58:10 | INFO | stdout | [32mINFO[0m:     127.0.0.1:44020 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 09:58:41 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 09:58:41 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940290.9800143)}
2024-04-01 09:58:41 | INFO | stdout | [32mINFO[0m:     127.0.0.1:49778 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 09:59:11 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 09:59:11 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940321.0198073)}
2024-04-01 09:59:11 | INFO | stdout | [32mINFO[0m:     127.0.0.1:34194 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 09:59:41 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 09:59:41 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940351.0542278)}
2024-04-01 09:59:41 | INFO | stdout | [32mINFO[0m:     127.0.0.1:41144 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:00:11 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:00:11 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940381.088293)}
2024-04-01 10:00:11 | INFO | stdout | [32mINFO[0m:     127.0.0.1:41046 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:00:41 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:00:41 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940411.1019921)}
2024-04-01 10:00:41 | INFO | stdout | [32mINFO[0m:     127.0.0.1:43532 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:01:11 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:01:11 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940441.1386273)}
2024-04-01 10:01:11 | INFO | stdout | [32mINFO[0m:     127.0.0.1:41662 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:01:41 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:01:41 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940471.1465135)}
2024-04-01 10:01:41 | INFO | stdout | [32mINFO[0m:     127.0.0.1:35686 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:02:11 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:02:11 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940501.1794775)}
2024-04-01 10:02:11 | INFO | stdout | [32mINFO[0m:     127.0.0.1:40204 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:02:41 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:02:41 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940531.211451)}
2024-04-01 10:02:41 | INFO | stdout | [32mINFO[0m:     127.0.0.1:57420 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:03:11 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:03:11 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940561.2434254)}
2024-04-01 10:03:11 | INFO | stdout | [32mINFO[0m:     127.0.0.1:45888 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:03:41 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:03:41 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940591.251265)}
2024-04-01 10:03:41 | INFO | stdout | [32mINFO[0m:     127.0.0.1:38636 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:04:11 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:04:11 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940621.283352)}
2024-04-01 10:04:11 | INFO | stdout | [32mINFO[0m:     127.0.0.1:44408 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:04:41 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:04:41 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940651.3154814)}
2024-04-01 10:04:41 | INFO | stdout | [32mINFO[0m:     127.0.0.1:38008 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:05:11 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:05:11 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940681.347509)}
2024-04-01 10:05:11 | INFO | stdout | [32mINFO[0m:     127.0.0.1:40112 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:05:41 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:05:41 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940711.3796287)}
2024-04-01 10:05:41 | INFO | stdout | [32mINFO[0m:     127.0.0.1:48470 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:06:11 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:06:11 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940741.4117312)}
2024-04-01 10:06:11 | INFO | stdout | [32mINFO[0m:     127.0.0.1:49186 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:06:41 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:06:41 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940771.4437363)}
2024-04-01 10:06:41 | INFO | stdout | [32mINFO[0m:     127.0.0.1:52572 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:07:11 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:07:11 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940801.4756377)}
2024-04-01 10:07:11 | INFO | stdout | [32mINFO[0m:     127.0.0.1:43138 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:07:41 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:07:41 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940831.481228)}
2024-04-01 10:07:41 | INFO | stdout | [32mINFO[0m:     127.0.0.1:52636 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:08:11 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:08:11 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940861.5131478)}
2024-04-01 10:08:11 | INFO | stdout | [32mINFO[0m:     127.0.0.1:51912 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:08:41 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:08:41 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940891.5450935)}
2024-04-01 10:08:41 | INFO | stdout | [32mINFO[0m:     127.0.0.1:57812 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:09:11 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:09:11 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940921.5771105)}
2024-04-01 10:09:11 | INFO | stdout | [32mINFO[0m:     127.0.0.1:50476 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:09:41 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:09:41 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940951.6073194)}
2024-04-01 10:09:41 | INFO | stdout | [32mINFO[0m:     127.0.0.1:57964 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:10:11 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:10:11 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711940981.6241982)}
2024-04-01 10:10:11 | INFO | stdout | [32mINFO[0m:     127.0.0.1:33644 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:10:41 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:10:41 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941011.6522217)}
2024-04-01 10:10:41 | INFO | stdout | [32mINFO[0m:     127.0.0.1:43210 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:11:11 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:11:11 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941041.6875532)}
2024-04-01 10:11:11 | INFO | stdout | [32mINFO[0m:     127.0.0.1:53292 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:11:41 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:11:41 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941071.7242446)}
2024-04-01 10:11:41 | INFO | stdout | [32mINFO[0m:     127.0.0.1:54680 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:12:11 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:12:11 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941101.752346)}
2024-04-01 10:12:11 | INFO | stdout | [32mINFO[0m:     127.0.0.1:37608 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:12:41 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:12:41 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941131.788454)}
2024-04-01 10:12:41 | INFO | stdout | [32mINFO[0m:     127.0.0.1:39218 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:13:11 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:13:11 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941161.7988725)}
2024-04-01 10:13:11 | INFO | stdout | [32mINFO[0m:     127.0.0.1:41854 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:13:41 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:13:41 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941191.815705)}
2024-04-01 10:13:41 | INFO | stdout | [32mINFO[0m:     127.0.0.1:42596 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:14:11 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:14:11 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941221.8527422)}
2024-04-01 10:14:11 | INFO | stdout | [32mINFO[0m:     127.0.0.1:59712 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:14:41 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:14:41 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941251.8886728)}
2024-04-01 10:14:41 | INFO | stdout | [32mINFO[0m:     127.0.0.1:45574 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:15:11 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:15:11 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941281.9252326)}
2024-04-01 10:15:11 | INFO | stdout | [32mINFO[0m:     127.0.0.1:59372 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:15:41 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:15:41 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941311.961748)}
2024-04-01 10:15:41 | INFO | stdout | [32mINFO[0m:     127.0.0.1:49314 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:16:12 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:16:12 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941341.9988494)}
2024-04-01 10:16:12 | INFO | stdout | [32mINFO[0m:     127.0.0.1:57638 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:16:42 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:16:42 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941372.0355034)}
2024-04-01 10:16:42 | INFO | stdout | [32mINFO[0m:     127.0.0.1:38040 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:17:12 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:17:12 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941402.0722911)}
2024-04-01 10:17:12 | INFO | stdout | [32mINFO[0m:     127.0.0.1:56064 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:17:42 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:17:42 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941432.1089575)}
2024-04-01 10:17:42 | INFO | stdout | [32mINFO[0m:     127.0.0.1:35418 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:18:12 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:18:12 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941462.1345744)}
2024-04-01 10:18:12 | INFO | stdout | [32mINFO[0m:     127.0.0.1:58288 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:18:42 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:18:42 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941492.170771)}
2024-04-01 10:18:42 | INFO | stdout | [32mINFO[0m:     127.0.0.1:44620 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:19:12 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:19:12 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941522.2073162)}
2024-04-01 10:19:12 | INFO | stdout | [32mINFO[0m:     127.0.0.1:43744 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:19:42 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:19:42 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941552.2425041)}
2024-04-01 10:19:42 | INFO | stdout | [32mINFO[0m:     127.0.0.1:47718 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:20:12 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:20:12 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941582.2627773)}
2024-04-01 10:20:12 | INFO | stdout | [32mINFO[0m:     127.0.0.1:53896 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:20:42 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:20:42 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941612.2996962)}
2024-04-01 10:20:42 | INFO | stdout | [32mINFO[0m:     127.0.0.1:33236 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:21:12 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:21:12 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941642.3227549)}
2024-04-01 10:21:12 | INFO | stdout | [32mINFO[0m:     127.0.0.1:58008 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:21:42 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:21:42 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941672.346689)}
2024-04-01 10:21:42 | INFO | stdout | [32mINFO[0m:     127.0.0.1:49994 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:22:12 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:22:12 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941702.383018)}
2024-04-01 10:22:12 | INFO | stdout | [32mINFO[0m:     127.0.0.1:35518 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:22:42 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:22:42 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941732.419573)}
2024-04-01 10:22:42 | INFO | stdout | [32mINFO[0m:     127.0.0.1:37388 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:23:12 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:23:12 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941762.4315238)}
2024-04-01 10:23:12 | INFO | stdout | [32mINFO[0m:     127.0.0.1:35056 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:23:42 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:23:42 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941792.4681203)}
2024-04-01 10:23:42 | INFO | stdout | [32mINFO[0m:     127.0.0.1:35892 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:24:12 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:24:12 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941822.5055232)}
2024-04-01 10:24:12 | INFO | stdout | [32mINFO[0m:     127.0.0.1:43406 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:24:42 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:24:42 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941852.5353105)}
2024-04-01 10:24:42 | INFO | stdout | [32mINFO[0m:     127.0.0.1:60616 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:25:12 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:25:12 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941882.5705647)}
2024-04-01 10:25:12 | INFO | stdout | [32mINFO[0m:     127.0.0.1:57476 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:25:42 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:25:42 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941912.606169)}
2024-04-01 10:25:42 | INFO | stdout | [32mINFO[0m:     127.0.0.1:55890 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:26:12 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:26:12 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941942.6202073)}
2024-04-01 10:26:12 | INFO | stdout | [32mINFO[0m:     127.0.0.1:39442 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:26:42 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:26:42 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711941972.6514852)}
2024-04-01 10:26:42 | INFO | stdout | [32mINFO[0m:     127.0.0.1:36016 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:27:12 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:27:12 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942002.686621)}
2024-04-01 10:27:12 | INFO | stdout | [32mINFO[0m:     127.0.0.1:47836 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:27:42 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:27:42 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942032.7025886)}
2024-04-01 10:27:42 | INFO | stdout | [32mINFO[0m:     127.0.0.1:37090 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:28:12 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:28:12 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942062.7393904)}
2024-04-01 10:28:12 | INFO | stdout | [32mINFO[0m:     127.0.0.1:57160 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:28:42 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:28:42 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942092.7763677)}
2024-04-01 10:28:42 | INFO | stdout | [32mINFO[0m:     127.0.0.1:37972 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:29:12 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:29:12 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942122.7962115)}
2024-04-01 10:29:12 | INFO | stdout | [32mINFO[0m:     127.0.0.1:34890 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:29:42 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:29:42 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942152.8320222)}
2024-04-01 10:29:42 | INFO | stdout | [32mINFO[0m:     127.0.0.1:40060 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:30:12 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:30:12 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942182.8575246)}
2024-04-01 10:30:12 | INFO | stdout | [32mINFO[0m:     127.0.0.1:49182 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:30:42 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:30:42 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942212.8924198)}
2024-04-01 10:30:42 | INFO | stdout | [32mINFO[0m:     127.0.0.1:33770 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:31:12 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:31:12 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942242.9120417)}
2024-04-01 10:31:12 | INFO | stdout | [32mINFO[0m:     127.0.0.1:48440 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:31:42 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:31:42 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942272.946278)}
2024-04-01 10:31:42 | INFO | stdout | [32mINFO[0m:     127.0.0.1:44774 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:32:13 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:32:13 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942302.9642131)}
2024-04-01 10:32:13 | INFO | stdout | [32mINFO[0m:     127.0.0.1:42826 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:32:43 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:32:43 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942333.0010576)}
2024-04-01 10:32:43 | INFO | stdout | [32mINFO[0m:     127.0.0.1:51104 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:33:13 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:33:13 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942363.0374298)}
2024-04-01 10:33:13 | INFO | stdout | [32mINFO[0m:     127.0.0.1:51670 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:33:43 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:33:43 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942393.0660424)}
2024-04-01 10:33:43 | INFO | stdout | [32mINFO[0m:     127.0.0.1:33934 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:34:13 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:34:13 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942423.0947962)}
2024-04-01 10:34:13 | INFO | stdout | [32mINFO[0m:     127.0.0.1:58558 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:34:43 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:34:43 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942453.1313598)}
2024-04-01 10:34:43 | INFO | stdout | [32mINFO[0m:     127.0.0.1:53822 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:35:13 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:35:13 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942483.1679864)}
2024-04-01 10:35:13 | INFO | stdout | [32mINFO[0m:     127.0.0.1:37712 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:35:43 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:35:43 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942513.2045372)}
2024-04-01 10:35:43 | INFO | stdout | [32mINFO[0m:     127.0.0.1:47690 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:36:13 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:36:13 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942543.238309)}
2024-04-01 10:36:13 | INFO | stdout | [32mINFO[0m:     127.0.0.1:58310 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:36:43 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:36:43 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942573.2732654)}
2024-04-01 10:36:43 | INFO | stdout | [32mINFO[0m:     127.0.0.1:42800 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:37:13 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:37:13 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942603.2807915)}
2024-04-01 10:37:13 | INFO | stdout | [32mINFO[0m:     127.0.0.1:48608 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:37:43 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:37:43 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942633.317229)}
2024-04-01 10:37:43 | INFO | stdout | [32mINFO[0m:     127.0.0.1:56758 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:38:13 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:38:13 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942663.353507)}
2024-04-01 10:38:13 | INFO | stdout | [32mINFO[0m:     127.0.0.1:41638 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:38:43 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:38:43 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942693.3900578)}
2024-04-01 10:38:43 | INFO | stdout | [32mINFO[0m:     127.0.0.1:37718 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:39:13 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:39:13 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942723.428617)}
2024-04-01 10:39:13 | INFO | stdout | [32mINFO[0m:     127.0.0.1:54112 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:39:43 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:39:43 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942753.463686)}
2024-04-01 10:39:43 | INFO | stdout | [32mINFO[0m:     127.0.0.1:47842 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:40:13 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:40:13 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942783.4704373)}
2024-04-01 10:40:13 | INFO | stdout | [32mINFO[0m:     127.0.0.1:39206 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:40:43 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:40:43 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942813.5062635)}
2024-04-01 10:40:43 | INFO | stdout | [32mINFO[0m:     127.0.0.1:59124 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:41:13 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:41:13 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942843.518537)}
2024-04-01 10:41:13 | INFO | stdout | [32mINFO[0m:     127.0.0.1:46328 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:41:43 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:41:43 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942873.5349388)}
2024-04-01 10:41:43 | INFO | stdout | [32mINFO[0m:     127.0.0.1:46324 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:42:13 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:42:13 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942903.5716448)}
2024-04-01 10:42:13 | INFO | stdout | [32mINFO[0m:     127.0.0.1:43012 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:42:43 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:42:43 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942933.6083987)}
2024-04-01 10:42:43 | INFO | stdout | [32mINFO[0m:     127.0.0.1:35306 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:43:13 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:43:13 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942963.6322317)}
2024-04-01 10:43:13 | INFO | stdout | [32mINFO[0m:     127.0.0.1:41590 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:43:43 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:43:43 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711942993.6560526)}
2024-04-01 10:43:43 | INFO | stdout | [32mINFO[0m:     127.0.0.1:45858 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:44:13 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:44:13 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943023.679504)}
2024-04-01 10:44:13 | INFO | stdout | [32mINFO[0m:     127.0.0.1:41362 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:44:43 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:44:43 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943053.6960845)}
2024-04-01 10:44:43 | INFO | stdout | [32mINFO[0m:     127.0.0.1:43464 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:45:13 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:45:13 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943083.716552)}
2024-04-01 10:45:13 | INFO | stdout | [32mINFO[0m:     127.0.0.1:42974 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:45:43 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:45:43 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943113.752722)}
2024-04-01 10:45:43 | INFO | stdout | [32mINFO[0m:     127.0.0.1:54888 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:46:13 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:46:13 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943143.789331)}
2024-04-01 10:46:13 | INFO | stdout | [32mINFO[0m:     127.0.0.1:41994 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:46:43 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:46:43 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943173.8199315)}
2024-04-01 10:46:43 | INFO | stdout | [32mINFO[0m:     127.0.0.1:55408 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:47:13 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:47:13 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943203.8553846)}
2024-04-01 10:47:13 | INFO | stdout | [32mINFO[0m:     127.0.0.1:47272 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:47:43 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:47:43 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943233.8919032)}
2024-04-01 10:47:43 | INFO | stdout | [32mINFO[0m:     127.0.0.1:36074 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:48:13 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:48:13 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943263.9260182)}
2024-04-01 10:48:13 | INFO | stdout | [32mINFO[0m:     127.0.0.1:54162 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:48:43 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:48:43 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943293.9604645)}
2024-04-01 10:48:43 | INFO | stdout | [32mINFO[0m:     127.0.0.1:48272 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:49:13 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:49:13 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943323.9673512)}
2024-04-01 10:49:13 | INFO | stdout | [32mINFO[0m:     127.0.0.1:36944 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:49:44 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:49:44 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943353.9917853)}
2024-04-01 10:49:44 | INFO | stdout | [32mINFO[0m:     127.0.0.1:56576 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:50:14 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:50:14 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943384.0392594)}
2024-04-01 10:50:14 | INFO | stdout | [32mINFO[0m:     127.0.0.1:38810 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:50:44 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:50:44 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943414.076156)}
2024-04-01 10:50:44 | INFO | stdout | [32mINFO[0m:     127.0.0.1:40752 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:51:14 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:51:14 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943444.114553)}
2024-04-01 10:51:14 | INFO | stdout | [32mINFO[0m:     127.0.0.1:43090 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:51:44 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:51:44 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943474.127381)}
2024-04-01 10:51:44 | INFO | stdout | [32mINFO[0m:     127.0.0.1:50630 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:52:14 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:52:14 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943504.1628752)}
2024-04-01 10:52:14 | INFO | stdout | [32mINFO[0m:     127.0.0.1:40826 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:52:44 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:52:44 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943534.187966)}
2024-04-01 10:52:44 | INFO | stdout | [32mINFO[0m:     127.0.0.1:38248 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:53:14 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:53:14 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943564.2228277)}
2024-04-01 10:53:14 | INFO | stdout | [32mINFO[0m:     127.0.0.1:53188 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:53:44 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:53:44 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943594.242267)}
2024-04-01 10:53:44 | INFO | stdout | [32mINFO[0m:     127.0.0.1:44218 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:54:14 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:54:14 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943624.2785907)}
2024-04-01 10:54:14 | INFO | stdout | [32mINFO[0m:     127.0.0.1:54788 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:54:44 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:54:44 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943654.2924855)}
2024-04-01 10:54:44 | INFO | stdout | [32mINFO[0m:     127.0.0.1:54484 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:55:14 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:55:14 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943684.3068469)}
2024-04-01 10:55:14 | INFO | stdout | [32mINFO[0m:     127.0.0.1:56884 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:55:44 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:55:44 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943714.3270779)}
2024-04-01 10:55:44 | INFO | stdout | [32mINFO[0m:     127.0.0.1:45660 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:56:14 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:56:14 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943744.363957)}
2024-04-01 10:56:14 | INFO | stdout | [32mINFO[0m:     127.0.0.1:53388 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:56:44 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:56:44 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943774.397348)}
2024-04-01 10:56:44 | INFO | stdout | [32mINFO[0m:     127.0.0.1:56408 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:57:14 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:57:14 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943804.4342442)}
2024-04-01 10:57:14 | INFO | stdout | [32mINFO[0m:     127.0.0.1:52982 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:57:44 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:57:44 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943834.4544291)}
2024-04-01 10:57:44 | INFO | stdout | [32mINFO[0m:     127.0.0.1:34570 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:58:14 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:58:14 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943864.4910274)}
2024-04-01 10:58:14 | INFO | stdout | [32mINFO[0m:     127.0.0.1:35798 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:58:44 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:58:44 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943894.5234113)}
2024-04-01 10:58:44 | INFO | stdout | [32mINFO[0m:     127.0.0.1:54650 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:59:14 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:59:14 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943924.5586994)}
2024-04-01 10:59:14 | INFO | stdout | [32mINFO[0m:     127.0.0.1:46154 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 10:59:44 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 10:59:44 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943954.5951734)}
2024-04-01 10:59:44 | INFO | stdout | [32mINFO[0m:     127.0.0.1:58348 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:00:14 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:00:14 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711943984.6316907)}
2024-04-01 11:00:14 | INFO | stdout | [32mINFO[0m:     127.0.0.1:46944 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:00:44 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:00:44 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944014.668233)}
2024-04-01 11:00:44 | INFO | stdout | [32mINFO[0m:     127.0.0.1:32838 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:01:14 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:01:14 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944044.7022715)}
2024-04-01 11:01:14 | INFO | stdout | [32mINFO[0m:     127.0.0.1:42762 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:01:44 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:01:44 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944074.7384415)}
2024-04-01 11:01:44 | INFO | stdout | [32mINFO[0m:     127.0.0.1:60476 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:02:14 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:02:14 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944104.7752628)}
2024-04-01 11:02:14 | INFO | stdout | [32mINFO[0m:     127.0.0.1:35350 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:02:44 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:02:44 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944134.811901)}
2024-04-01 11:02:44 | INFO | stdout | [32mINFO[0m:     127.0.0.1:44584 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:03:14 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:03:14 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944164.830961)}
2024-04-01 11:03:14 | INFO | stdout | [32mINFO[0m:     127.0.0.1:53962 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:03:44 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:03:44 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944194.8475213)}
2024-04-01 11:03:44 | INFO | stdout | [32mINFO[0m:     127.0.0.1:36960 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:04:14 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:04:14 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944224.8801515)}
2024-04-01 11:04:14 | INFO | stdout | [32mINFO[0m:     127.0.0.1:48548 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:04:44 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:04:44 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944254.9051635)}
2024-04-01 11:04:44 | INFO | stdout | [32mINFO[0m:     127.0.0.1:53692 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:05:14 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:05:14 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944284.9352446)}
2024-04-01 11:05:14 | INFO | stdout | [32mINFO[0m:     127.0.0.1:54556 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:05:45 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:05:45 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944314.9718237)}
2024-04-01 11:05:45 | INFO | stdout | [32mINFO[0m:     127.0.0.1:50304 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:06:15 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:06:15 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944345.0091753)}
2024-04-01 11:06:15 | INFO | stdout | [32mINFO[0m:     127.0.0.1:46652 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:06:45 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:06:45 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944375.0304897)}
2024-04-01 11:06:45 | INFO | stdout | [32mINFO[0m:     127.0.0.1:47728 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:07:15 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:07:15 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944405.0672636)}
2024-04-01 11:07:15 | INFO | stdout | [32mINFO[0m:     127.0.0.1:55576 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:07:45 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:07:45 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944435.0881221)}
2024-04-01 11:07:45 | INFO | stdout | [32mINFO[0m:     127.0.0.1:52492 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:08:15 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:08:15 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944465.1244724)}
2024-04-01 11:08:15 | INFO | stdout | [32mINFO[0m:     127.0.0.1:49880 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:08:45 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:08:45 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944495.1585937)}
2024-04-01 11:08:45 | INFO | stdout | [32mINFO[0m:     127.0.0.1:40434 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:09:15 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:09:15 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944525.1951733)}
2024-04-01 11:09:15 | INFO | stdout | [32mINFO[0m:     127.0.0.1:59620 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:09:45 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:09:45 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944555.2297618)}
2024-04-01 11:09:45 | INFO | stdout | [32mINFO[0m:     127.0.0.1:34216 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:10:15 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:10:15 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944585.266437)}
2024-04-01 11:10:15 | INFO | stdout | [32mINFO[0m:     127.0.0.1:60424 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:10:45 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:10:45 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944615.2929654)}
2024-04-01 11:10:45 | INFO | stdout | [32mINFO[0m:     127.0.0.1:52344 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:11:15 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:11:15 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944645.3195233)}
2024-04-01 11:11:15 | INFO | stdout | [32mINFO[0m:     127.0.0.1:49708 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:11:45 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:11:45 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944675.326614)}
2024-04-01 11:11:45 | INFO | stdout | [32mINFO[0m:     127.0.0.1:40528 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:12:15 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:12:15 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944705.3626394)}
2024-04-01 11:12:15 | INFO | stdout | [32mINFO[0m:     127.0.0.1:41492 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:12:45 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:12:45 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944735.3731534)}
2024-04-01 11:12:45 | INFO | stdout | [32mINFO[0m:     127.0.0.1:60166 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:13:15 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:13:15 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944765.3996885)}
2024-04-01 11:13:15 | INFO | stdout | [32mINFO[0m:     127.0.0.1:49966 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:13:45 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:13:45 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944795.437997)}
2024-04-01 11:13:45 | INFO | stdout | [32mINFO[0m:     127.0.0.1:40980 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:14:15 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:14:15 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944825.4767237)}
2024-04-01 11:14:15 | INFO | stdout | [32mINFO[0m:     127.0.0.1:35338 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:14:45 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:14:45 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944855.5136166)}
2024-04-01 11:14:45 | INFO | stdout | [32mINFO[0m:     127.0.0.1:36518 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:15:15 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:15:15 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944885.5474737)}
2024-04-01 11:15:15 | INFO | stdout | [32mINFO[0m:     127.0.0.1:42244 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:15:45 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:15:45 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944915.5787983)}
2024-04-01 11:15:45 | INFO | stdout | [32mINFO[0m:     127.0.0.1:38148 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:16:15 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:16:15 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944945.5908532)}
2024-04-01 11:16:15 | INFO | stdout | [32mINFO[0m:     127.0.0.1:58320 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:16:45 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:16:45 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711944975.6232238)}
2024-04-01 11:16:45 | INFO | stdout | [32mINFO[0m:     127.0.0.1:55720 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:17:15 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:17:15 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711945005.6575441)}
2024-04-01 11:17:15 | INFO | stdout | [32mINFO[0m:     127.0.0.1:55748 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:17:45 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:17:45 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711945035.6937785)}
2024-04-01 11:17:45 | INFO | stdout | [32mINFO[0m:     127.0.0.1:39406 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:18:15 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:18:15 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711945065.730422)}
2024-04-01 11:18:15 | INFO | stdout | [32mINFO[0m:     127.0.0.1:39368 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:18:45 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:18:45 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711945095.7670999)}
2024-04-01 11:18:45 | INFO | stdout | [32mINFO[0m:     127.0.0.1:40872 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:19:15 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:19:15 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711945125.8035667)}
2024-04-01 11:19:15 | INFO | stdout | [32mINFO[0m:     127.0.0.1:58368 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:19:45 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:19:45 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711945155.8400104)}
2024-04-01 11:19:45 | INFO | stdout | [32mINFO[0m:     127.0.0.1:36386 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:20:15 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:20:15 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711945185.8616364)}
2024-04-01 11:20:15 | INFO | stdout | [32mINFO[0m:     127.0.0.1:41980 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:20:45 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:20:45 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711945215.8946004)}
2024-04-01 11:20:45 | INFO | stdout | [32mINFO[0m:     127.0.0.1:38480 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:21:15 | INFO | stdout | ----worker_name:  http://localhost:21008
2024-04-01 11:21:15 | INFO | stdout | ----self.worker_info:  {'http://localhost:21008': WorkerInfo(model_names=['llava_plus_v0_7b'], speed=1, queue_length=0, check_heart_beat=True, last_heart_beat=1711945245.9309163)}
2024-04-01 11:21:15 | INFO | stdout | [32mINFO[0m:     127.0.0.1:37320 - "[1mPOST /receive_heart_beat HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:21:22 | ERROR | stderr | [32mINFO[0m:     Shutting down
2024-04-01 11:21:22 | ERROR | stderr | [32mINFO[0m:     Waiting for application shutdown.
2024-04-01 11:21:22 | ERROR | stderr | [32mINFO[0m:     Application shutdown complete.
2024-04-01 11:21:22 | ERROR | stderr | [32mINFO[0m:     Finished server process [[36m24083[0m]
2024-04-01 11:21:22 | ERROR | stderr | Exception ignored in: <module 'threading' from '/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py'>
2024-04-01 11:21:22 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 11:21:22 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1477, in _shutdown
2024-04-01 11:21:22 | ERROR | stderr |     lock.acquire()
2024-04-01 11:21:22 | ERROR | stderr | KeyboardInterrupt:
2024-04-01 11:39:52 | INFO | stdout | Using conversation: conv_vicuna_v1
2024-04-01 11:39:52 | INFO | stdout | [32mINFO[0m:     127.0.0.1:42630 - "[1mPOST /refresh_all_workers HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:39:52 | INFO | stdout | [32mINFO[0m:     127.0.0.1:42642 - "[1mPOST /list_models HTTP/1.1[0m" [32m200 OK[0m
2024-04-01 11:39:52 | INFO | app_server | Models: []
2024-04-01 11:39:52 | INFO | stdout | []
2024-04-01 11:39:52 | INFO | stdout | Running on local URL:  http://0.0.0.0:8888
2024-04-01 11:39:52 | INFO | stdout | 
2024-04-01 11:39:52 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 11:39:56 | INFO | app_server | load_demo. ip: 192.168.6.78. params: {}
2024-04-01 11:40:02 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 13:04:06 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 13:04:06 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 24, in <module>
2024-04-01 13:04:06 | ERROR | stderr |     demo = build_demo()
2024-04-01 13:04:06 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 5, in build_demo
2024-04-01 13:04:06 | ERROR | stderr |     upload_file_button = gradio.Button(value="Upload file", visible=True)
2024-04-01 13:04:06 | ERROR | stderr | NameError: name 'gradio' is not defined
2024-04-01 13:04:22 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 13:04:22 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 25, in <module>
2024-04-01 13:04:22 | ERROR | stderr |     demo.queue(
2024-04-01 13:04:22 | ERROR | stderr | AttributeError: 'NoneType' object has no attribute 'queue'
2024-04-01 13:04:58 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 13:04:58 | INFO | stdout | 
2024-04-01 13:04:58 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 13:05:58 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 13:06:17 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 13:06:17 | INFO | stdout | 
2024-04-01 13:06:17 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 13:07:22 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 13:07:41 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 13:07:41 | INFO | stdout | 
2024-04-01 13:07:41 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 13:10:44 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 13:11:04 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 13:11:04 | INFO | stdout | 
2024-04-01 13:11:04 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 13:32:00 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 13:32:16 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 13:32:16 | INFO | stdout | 
2024-04-01 13:32:16 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 13:41:43 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 13:42:01 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 13:42:01 | INFO | stdout | 
2024-04-01 13:42:01 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 13:42:01 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 13:42:01 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 33, in <module>
2024-04-01 13:42:01 | ERROR | stderr |     demo.queue(
2024-04-01 13:42:01 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1964, in launch
2024-04-01 13:42:01 | ERROR | stderr |     analytics.launched_analytics(self, data)
2024-04-01 13:42:01 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/analytics.py", line 122, in launched_analytics
2024-04-01 13:42:01 | ERROR | stderr |     inputs_telemetry = inputs_telemetry + [
2024-04-01 13:42:01 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/analytics.py", line 123, in <listcomp>
2024-04-01 13:42:01 | ERROR | stderr |     str(blocks.blocks[y]) for y in x["inputs"]
2024-04-01 13:42:01 | ERROR | stderr | KeyError: 3
2024-04-01 13:42:55 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 13:42:55 | INFO | stdout | 
2024-04-01 13:42:55 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 13:46:00 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 13:46:15 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 13:46:15 | INFO | stdout | 
2024-04-01 13:46:15 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 13:46:15 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 13:46:15 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 34, in <module>
2024-04-01 13:46:15 | ERROR | stderr |     demo.queue(
2024-04-01 13:46:15 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1964, in launch
2024-04-01 13:46:15 | ERROR | stderr |     analytics.launched_analytics(self, data)
2024-04-01 13:46:15 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/analytics.py", line 125, in launched_analytics
2024-04-01 13:46:15 | ERROR | stderr |     outputs_telemetry = outputs_telemetry + [
2024-04-01 13:46:15 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/analytics.py", line 126, in <listcomp>
2024-04-01 13:46:15 | ERROR | stderr |     str(blocks.blocks[y]) for y in x["outputs"]
2024-04-01 13:46:15 | ERROR | stderr | KeyError: 2
2024-04-01 13:46:59 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 13:46:59 | INFO | stdout | 
2024-04-01 13:46:59 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 13:50:24 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 13:50:24 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 13:50:24 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2058, in block_thread
2024-04-01 13:50:24 | ERROR | stderr |     time.sleep(0.1)
2024-04-01 13:50:24 | ERROR | stderr | KeyboardInterrupt
2024-04-01 13:50:24 | ERROR | stderr | 
2024-04-01 13:50:24 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-01 13:50:24 | ERROR | stderr | 
2024-04-01 13:50:24 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 13:50:24 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 35, in <module>
2024-04-01 13:50:24 | ERROR | stderr |     demo.queue(
2024-04-01 13:50:24 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1975, in launch
2024-04-01 13:50:24 | ERROR | stderr |     self.block_thread()
2024-04-01 13:50:24 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2061, in block_thread
2024-04-01 13:50:24 | ERROR | stderr |     self.server.close()
2024-04-01 13:50:24 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/networking.py", line 43, in close
2024-04-01 13:50:24 | ERROR | stderr |     self.thread.join()
2024-04-01 13:50:24 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-01 13:50:24 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-01 13:50:24 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-01 13:50:24 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-01 13:50:24 | ERROR | stderr | KeyboardInterrupt
2024-04-01 13:50:38 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 13:50:38 | INFO | stdout | 
2024-04-01 13:50:38 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 14:05:23 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 14:05:32 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 14:05:32 | INFO | stdout | 
2024-04-01 14:05:32 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 14:05:59 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 14:06:16 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 14:06:16 | INFO | stdout | 
2024-04-01 14:06:16 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 14:06:51 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 14:07:09 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 14:07:09 | INFO | stdout | 
2024-04-01 14:07:09 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 14:11:58 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 14:11:58 | ERROR | stderr | Error in atexit._run_exitfuncs:
2024-04-01 14:11:58 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 14:11:58 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/deepspeed/ops/transformer/inference/triton/matmul_ext.py", line 69, in put
2024-04-01 14:11:58 | ERROR | stderr |     os.rename(self.file_path + ".tmp", self.file_path)
2024-04-01 14:11:58 | ERROR | stderr | KeyboardInterrupt
2024-04-01 14:12:16 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 14:12:16 | INFO | stdout | 
2024-04-01 14:12:16 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 14:12:29 | INFO | stdout | [0]
2024-04-01 14:12:31 | INFO | stdout | [0, 1]
2024-04-01 14:12:32 | INFO | stdout | [0, 1, 2]
2024-04-01 14:12:33 | INFO | stdout | [0, 1]
2024-04-01 14:12:33 | INFO | stdout | [0]
2024-04-01 14:12:34 | INFO | stdout | []
2024-04-01 14:13:59 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 14:14:06 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 14:14:06 | INFO | stdout | 
2024-04-01 14:14:06 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 14:14:12 | INFO | stdout | [0]
2024-04-01 14:14:13 | INFO | stdout | [0, 1]
2024-04-01 14:14:13 | INFO | stdout | [0, 1, 2]
2024-04-01 14:14:15 | INFO | stdout | [0, 1]
2024-04-01 14:14:16 | INFO | stdout | [0]
2024-04-01 14:14:16 | INFO | stdout | []
2024-04-01 14:17:48 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 14:18:07 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 14:18:07 | INFO | stdout | 
2024-04-01 14:18:07 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 14:18:54 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 14:19:12 | INFO | stdout | []
2024-04-01 14:19:12 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 14:19:12 | INFO | stdout | 
2024-04-01 14:19:12 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 14:21:36 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 14:21:52 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:766: UserWarning: Expected 1 arguments for function <function get_checkbox_value at 0x7f0f5a6f2820>, received 0.
2024-04-01 14:21:52 | ERROR | stderr |   warnings.warn(
2024-04-01 14:21:52 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:770: UserWarning: Expected at least 1 arguments for function <function get_checkbox_value at 0x7f0f5a6f2820>, received 0.
2024-04-01 14:21:52 | ERROR | stderr |   warnings.warn(
2024-04-01 14:21:52 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 14:21:52 | INFO | stdout | 
2024-04-01 14:21:52 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 14:22:26 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 14:22:46 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 14:22:46 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 40, in <module>
2024-04-01 14:22:46 | ERROR | stderr |     demo = build_demo()
2024-04-01 14:22:46 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 29, in build_demo
2024-04-01 14:22:46 | ERROR | stderr |     upload_button.click(get_checkbox_value, list_file, aaa)
2024-04-01 14:22:46 | ERROR | stderr | NameError: name 'aaa' is not defined
2024-04-01 14:23:15 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:766: UserWarning: Expected 1 arguments for function <function get_checkbox_value at 0x7fd56ec8d8b0>, received 0.
2024-04-01 14:23:15 | ERROR | stderr |   warnings.warn(
2024-04-01 14:23:15 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:770: UserWarning: Expected at least 1 arguments for function <function get_checkbox_value at 0x7fd56ec8d8b0>, received 0.
2024-04-01 14:23:15 | ERROR | stderr |   warnings.warn(
2024-04-01 14:23:15 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 14:23:15 | INFO | stdout | 
2024-04-01 14:23:15 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 14:23:55 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 14:24:02 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:766: UserWarning: Expected 1 arguments for function <function get_checkbox_value at 0x7fa0d316b790>, received 0.
2024-04-01 14:24:02 | ERROR | stderr |   warnings.warn(
2024-04-01 14:24:02 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:770: UserWarning: Expected at least 1 arguments for function <function get_checkbox_value at 0x7fa0d316b790>, received 0.
2024-04-01 14:24:02 | ERROR | stderr |   warnings.warn(
2024-04-01 14:24:02 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 14:24:02 | INFO | stdout | 
2024-04-01 14:24:02 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 14:24:15 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/helpers.py:661: UserWarning: Unexpected argument. Filling with None.
2024-04-01 14:24:15 | ERROR | stderr |   warnings.warn("Unexpected argument. Filling with None.")
2024-04-01 14:24:15 | INFO | stdout | None
2024-04-01 14:24:17 | INFO | stdout | None
2024-04-01 14:24:18 | INFO | stdout | None
2024-04-01 14:24:18 | INFO | stdout | None
2024-04-01 14:24:19 | INFO | stdout | None
2024-04-01 14:24:19 | INFO | stdout | None
2024-04-01 14:24:28 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 14:28:24 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 14:28:24 | INFO | stdout | 
2024-04-01 14:28:24 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 14:28:35 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 14:28:35 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-01 14:28:35 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-01 14:28:35 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1352, in process_api
2024-04-01 14:28:35 | ERROR | stderr |     result = await self.call_function(
2024-04-01 14:28:35 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1077, in call_function
2024-04-01 14:28:35 | ERROR | stderr |     prediction = await anyio.to_thread.run_sync(
2024-04-01 14:28:35 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/to_thread.py", line 56, in run_sync
2024-04-01 14:28:35 | ERROR | stderr |     return await get_async_backend().run_sync_in_worker_thread(
2024-04-01 14:28:35 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 2134, in run_sync_in_worker_thread
2024-04-01 14:28:35 | ERROR | stderr |     return await future
2024-04-01 14:28:35 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 851, in run
2024-04-01 14:28:35 | ERROR | stderr |     result = context.run(func, *args)
2024-04-01 14:28:35 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 6, in upload_file
2024-04-01 14:28:35 | ERROR | stderr |     return gr.CheckboxGroup.update(choices=file_paths, value=choices)
2024-04-01 14:28:35 | ERROR | stderr | NameError: name 'choices' is not defined
2024-04-01 14:28:56 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 14:29:06 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 14:29:06 | INFO | stdout | 
2024-04-01 14:29:06 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 14:30:08 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 14:30:24 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 14:30:24 | INFO | stdout | 
2024-04-01 14:30:24 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 14:34:48 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 14:35:07 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 14:35:07 | INFO | stdout | 
2024-04-01 14:35:07 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 14:35:18 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 14:35:18 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-01 14:35:18 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-01 14:35:18 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1350, in process_api
2024-04-01 14:35:18 | ERROR | stderr |     inputs = self.preprocess_data(fn_index, inputs, state)
2024-04-01 14:35:18 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1200, in preprocess_data
2024-04-01 14:35:18 | ERROR | stderr |     processed_input.append(block.preprocess(inputs[i]))
2024-04-01 14:35:18 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/components/file.py", line 215, in preprocess
2024-04-01 14:35:18 | ERROR | stderr |     return process_single_file(x[0])
2024-04-01 14:35:18 | ERROR | stderr | IndexError: list index out of range
2024-04-01 14:35:30 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 14:35:36 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 14:35:36 | INFO | stdout | 
2024-04-01 14:35:36 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 14:36:37 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 14:36:45 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 14:36:45 | INFO | stdout | 
2024-04-01 14:36:45 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 14:37:16 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 14:37:35 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 14:37:35 | INFO | stdout | 
2024-04-01 14:37:35 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 14:39:42 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 14:39:50 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 14:39:50 | INFO | stdout | 
2024-04-01 14:39:50 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 14:49:15 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 14:49:32 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 14:49:32 | INFO | stdout | 
2024-04-01 14:49:32 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 14:49:42 | INFO | stdout | []
2024-04-01 14:49:46 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 14:49:46 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-01 14:49:46 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-01 14:49:46 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1350, in process_api
2024-04-01 14:49:46 | ERROR | stderr |     inputs = self.preprocess_data(fn_index, inputs, state)
2024-04-01 14:49:46 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1200, in preprocess_data
2024-04-01 14:49:46 | ERROR | stderr |     processed_input.append(block.preprocess(inputs[i]))
2024-04-01 14:49:46 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/components/checkboxgroup.py", line 155, in preprocess
2024-04-01 14:49:46 | ERROR | stderr |     return [self.choices.index(choice) for choice in x]
2024-04-01 14:49:46 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/components/checkboxgroup.py", line 155, in <listcomp>
2024-04-01 14:49:46 | ERROR | stderr |     return [self.choices.index(choice) for choice in x]
2024-04-01 14:49:46 | ERROR | stderr | ValueError: 'Tay vÆ°Æ¡n camera_SB4.pdf' is not in list
2024-04-01 14:49:58 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 14:49:58 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-01 14:49:58 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-01 14:49:58 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1350, in process_api
2024-04-01 14:49:58 | ERROR | stderr |     inputs = self.preprocess_data(fn_index, inputs, state)
2024-04-01 14:49:58 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1200, in preprocess_data
2024-04-01 14:49:58 | ERROR | stderr |     processed_input.append(block.preprocess(inputs[i]))
2024-04-01 14:49:58 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/components/checkboxgroup.py", line 155, in preprocess
2024-04-01 14:49:58 | ERROR | stderr |     return [self.choices.index(choice) for choice in x]
2024-04-01 14:49:58 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/components/checkboxgroup.py", line 155, in <listcomp>
2024-04-01 14:49:58 | ERROR | stderr |     return [self.choices.index(choice) for choice in x]
2024-04-01 14:49:58 | ERROR | stderr | ValueError: 'Tay vÆ°Æ¡n camera_SB4.pdf' is not in list
2024-04-01 14:50:19 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 14:50:19 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-01 14:50:19 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-01 14:50:19 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1350, in process_api
2024-04-01 14:50:19 | ERROR | stderr |     inputs = self.preprocess_data(fn_index, inputs, state)
2024-04-01 14:50:19 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1200, in preprocess_data
2024-04-01 14:50:19 | ERROR | stderr |     processed_input.append(block.preprocess(inputs[i]))
2024-04-01 14:50:19 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/components/checkboxgroup.py", line 155, in preprocess
2024-04-01 14:50:19 | ERROR | stderr |     return [self.choices.index(choice) for choice in x]
2024-04-01 14:50:19 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/components/checkboxgroup.py", line 155, in <listcomp>
2024-04-01 14:50:19 | ERROR | stderr |     return [self.choices.index(choice) for choice in x]
2024-04-01 14:50:19 | ERROR | stderr | ValueError: 'Tay vÆ°Æ¡n camera_SB4.pdf' is not in list
2024-04-01 14:50:54 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 14:51:14 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 14:51:14 | INFO | stdout | 
2024-04-01 14:51:14 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 14:51:21 | INFO | stdout | []
2024-04-01 14:51:23 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 14:51:23 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-01 14:51:23 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-01 14:51:23 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1350, in process_api
2024-04-01 14:51:23 | ERROR | stderr |     inputs = self.preprocess_data(fn_index, inputs, state)
2024-04-01 14:51:23 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1200, in preprocess_data
2024-04-01 14:51:23 | ERROR | stderr |     processed_input.append(block.preprocess(inputs[i]))
2024-04-01 14:51:23 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/components/checkboxgroup.py", line 155, in preprocess
2024-04-01 14:51:23 | ERROR | stderr |     return [self.choices.index(choice) for choice in x]
2024-04-01 14:51:23 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/components/checkboxgroup.py", line 155, in <listcomp>
2024-04-01 14:51:23 | ERROR | stderr |     return [self.choices.index(choice) for choice in x]
2024-04-01 14:51:23 | ERROR | stderr | ValueError: 'Tay vÆ°Æ¡n camera_SB4.pdf' is not in list
2024-04-01 14:51:44 | INFO | stdout | []
2024-04-01 14:51:51 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 14:51:51 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-01 14:51:51 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-01 14:51:51 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1350, in process_api
2024-04-01 14:51:51 | ERROR | stderr |     inputs = self.preprocess_data(fn_index, inputs, state)
2024-04-01 14:51:51 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1200, in preprocess_data
2024-04-01 14:51:51 | ERROR | stderr |     processed_input.append(block.preprocess(inputs[i]))
2024-04-01 14:51:51 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/components/checkboxgroup.py", line 155, in preprocess
2024-04-01 14:51:51 | ERROR | stderr |     return [self.choices.index(choice) for choice in x]
2024-04-01 14:51:51 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/components/checkboxgroup.py", line 155, in <listcomp>
2024-04-01 14:51:51 | ERROR | stderr |     return [self.choices.index(choice) for choice in x]
2024-04-01 14:51:51 | ERROR | stderr | ValueError: 'CV-HoÃ ng VÅ© An-AI.pdf' is not in list
2024-04-01 14:53:51 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 14:53:51 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 14:53:51 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2058, in block_thread
2024-04-01 14:53:51 | ERROR | stderr |     time.sleep(0.1)
2024-04-01 14:53:51 | ERROR | stderr | KeyboardInterrupt
2024-04-01 14:53:51 | ERROR | stderr | 
2024-04-01 14:53:51 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-01 14:53:51 | ERROR | stderr | 
2024-04-01 14:53:51 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 14:53:51 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 46, in <module>
2024-04-01 14:53:51 | ERROR | stderr |     demo.queue(
2024-04-01 14:53:51 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1975, in launch
2024-04-01 14:53:51 | ERROR | stderr |     self.block_thread()
2024-04-01 14:53:51 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2061, in block_thread
2024-04-01 14:53:51 | ERROR | stderr |     self.server.close()
2024-04-01 14:53:51 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/networking.py", line 43, in close
2024-04-01 14:53:51 | ERROR | stderr |     self.thread.join()
2024-04-01 14:53:51 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-01 14:53:51 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-01 14:53:51 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-01 14:53:51 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-01 14:53:51 | ERROR | stderr | KeyboardInterrupt
2024-04-01 14:54:01 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 14:54:01 | INFO | stdout | 
2024-04-01 14:54:01 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 14:54:07 | INFO | stdout | [0]
2024-04-01 14:54:08 | INFO | stdout | [0, 1]
2024-04-01 14:54:08 | INFO | stdout | [0, 1, 2]
2024-04-01 14:54:09 | INFO | stdout | [0, 1]
2024-04-01 14:54:09 | INFO | stdout | [0]
2024-04-01 14:54:09 | INFO | stdout | []
2024-04-01 14:55:08 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 14:55:27 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 14:55:27 | INFO | stdout | 
2024-04-01 14:55:27 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 14:55:34 | INFO | stdout | []
2024-04-01 14:55:35 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 14:55:35 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-01 14:55:35 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-01 14:55:35 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1350, in process_api
2024-04-01 14:55:35 | ERROR | stderr |     inputs = self.preprocess_data(fn_index, inputs, state)
2024-04-01 14:55:35 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1200, in preprocess_data
2024-04-01 14:55:35 | ERROR | stderr |     processed_input.append(block.preprocess(inputs[i]))
2024-04-01 14:55:35 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/components/checkboxgroup.py", line 155, in preprocess
2024-04-01 14:55:35 | ERROR | stderr |     return [self.choices.index(choice) for choice in x]
2024-04-01 14:55:35 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/components/checkboxgroup.py", line 155, in <listcomp>
2024-04-01 14:55:35 | ERROR | stderr |     return [self.choices.index(choice) for choice in x]
2024-04-01 14:55:35 | ERROR | stderr | ValueError: 'CV-HoÃ ng VÅ© An-AI.pdf' is not in list
2024-04-01 14:56:04 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 14:56:04 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-01 14:56:04 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-01 14:56:04 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1350, in process_api
2024-04-01 14:56:04 | ERROR | stderr |     inputs = self.preprocess_data(fn_index, inputs, state)
2024-04-01 14:56:04 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1200, in preprocess_data
2024-04-01 14:56:04 | ERROR | stderr |     processed_input.append(block.preprocess(inputs[i]))
2024-04-01 14:56:04 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/components/checkboxgroup.py", line 155, in preprocess
2024-04-01 14:56:04 | ERROR | stderr |     return [self.choices.index(choice) for choice in x]
2024-04-01 14:56:04 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/components/checkboxgroup.py", line 155, in <listcomp>
2024-04-01 14:56:04 | ERROR | stderr |     return [self.choices.index(choice) for choice in x]
2024-04-01 14:56:04 | ERROR | stderr | ValueError: 'CV-HoÃ ng VÅ© An-AI.pdf' is not in list
2024-04-01 14:56:05 | INFO | stdout | []
2024-04-01 14:56:09 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 14:56:09 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-01 14:56:09 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-01 14:56:09 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1350, in process_api
2024-04-01 14:56:09 | ERROR | stderr |     inputs = self.preprocess_data(fn_index, inputs, state)
2024-04-01 14:56:09 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1200, in preprocess_data
2024-04-01 14:56:09 | ERROR | stderr |     processed_input.append(block.preprocess(inputs[i]))
2024-04-01 14:56:09 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/components/checkboxgroup.py", line 155, in preprocess
2024-04-01 14:56:09 | ERROR | stderr |     return [self.choices.index(choice) for choice in x]
2024-04-01 14:56:09 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/components/checkboxgroup.py", line 155, in <listcomp>
2024-04-01 14:56:09 | ERROR | stderr |     return [self.choices.index(choice) for choice in x]
2024-04-01 14:56:09 | ERROR | stderr | ValueError: 'CV-HoÃ ng VÅ© An-AI.pdf' is not in list
2024-04-01 14:56:10 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 14:56:10 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-01 14:56:10 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-01 14:56:10 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1350, in process_api
2024-04-01 14:56:10 | ERROR | stderr |     inputs = self.preprocess_data(fn_index, inputs, state)
2024-04-01 14:56:10 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1200, in preprocess_data
2024-04-01 14:56:10 | ERROR | stderr |     processed_input.append(block.preprocess(inputs[i]))
2024-04-01 14:56:10 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/components/checkboxgroup.py", line 155, in preprocess
2024-04-01 14:56:10 | ERROR | stderr |     return [self.choices.index(choice) for choice in x]
2024-04-01 14:56:10 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/components/checkboxgroup.py", line 155, in <listcomp>
2024-04-01 14:56:10 | ERROR | stderr |     return [self.choices.index(choice) for choice in x]
2024-04-01 14:56:10 | ERROR | stderr | ValueError: 'CV-HoÃ ng VÅ© An-AI.pdf' is not in list
2024-04-01 14:56:17 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 14:56:55 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 14:56:55 | INFO | stdout | 
2024-04-01 14:56:55 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 14:57:04 | INFO | stdout | [1]
2024-04-01 14:57:09 | INFO | stdout | [1]
2024-04-01 14:57:09 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 14:57:09 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 14:57:09 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-01 14:57:09 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-01 14:57:09 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1350, in process_api
2024-04-01 14:57:09 | ERROR | stderr |     inputs = self.preprocess_data(fn_index, inputs, state)
2024-04-01 14:57:09 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1200, in preprocess_data
2024-04-01 14:57:09 | ERROR | stderr |     processed_input.append(block.preprocess(inputs[i]))
2024-04-01 14:57:09 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/components/checkboxgroup.py", line 155, in preprocess
2024-04-01 14:57:09 | ERROR | stderr |     return [self.choices.index(choice) for choice in x]
2024-04-01 14:57:09 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/components/checkboxgroup.py", line 155, in <listcomp>
2024-04-01 14:57:09 | ERROR | stderr |     return [self.choices.index(choice) for choice in x]
2024-04-01 14:57:09 | ERROR | stderr | ValueError: 'CV-HoÃ ng VÅ© An-AI.pdf' is not in list
2024-04-01 14:57:21 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 14:57:21 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-01 14:57:21 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-01 14:57:21 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1350, in process_api
2024-04-01 14:57:21 | ERROR | stderr |     inputs = self.preprocess_data(fn_index, inputs, state)
2024-04-01 14:57:21 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1200, in preprocess_data
2024-04-01 14:57:21 | ERROR | stderr |     processed_input.append(block.preprocess(inputs[i]))
2024-04-01 14:57:21 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/components/checkboxgroup.py", line 155, in preprocess
2024-04-01 14:57:21 | ERROR | stderr |     return [self.choices.index(choice) for choice in x]
2024-04-01 14:57:21 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/components/checkboxgroup.py", line 155, in <listcomp>
2024-04-01 14:57:21 | ERROR | stderr |     return [self.choices.index(choice) for choice in x]
2024-04-01 14:57:21 | ERROR | stderr | ValueError: 'CV-HoÃ ng VÅ© An-AI.pdf' is not in list
2024-04-01 14:58:15 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 14:58:15 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 14:58:15 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2058, in block_thread
2024-04-01 14:58:15 | ERROR | stderr |     time.sleep(0.1)
2024-04-01 14:58:15 | ERROR | stderr | KeyboardInterrupt
2024-04-01 14:58:15 | ERROR | stderr | 
2024-04-01 14:58:15 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-01 14:58:15 | ERROR | stderr | 
2024-04-01 14:58:15 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 14:58:15 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 47, in <module>
2024-04-01 14:58:15 | ERROR | stderr |     demo.queue(
2024-04-01 14:58:15 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1975, in launch
2024-04-01 14:58:15 | ERROR | stderr |     self.block_thread()
2024-04-01 14:58:15 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2061, in block_thread
2024-04-01 14:58:15 | ERROR | stderr |     self.server.close()
2024-04-01 14:58:15 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/networking.py", line 43, in close
2024-04-01 14:58:15 | ERROR | stderr |     self.thread.join()
2024-04-01 14:58:15 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-01 14:58:15 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-01 14:58:15 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-01 14:58:15 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-01 14:58:15 | ERROR | stderr | KeyboardInterrupt
2024-04-01 14:58:23 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 14:58:23 | INFO | stdout | 
2024-04-01 14:58:23 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 14:58:29 | INFO | stdout | ['doc3.pdf']
2024-04-01 14:58:30 | INFO | stdout | ['doc3.pdf']
2024-04-01 14:58:30 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 14:58:30 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 14:58:35 | INFO | stdout | ['BQP.pdf']
2024-04-01 14:58:36 | INFO | stdout | []
2024-04-01 14:58:36 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf']
2024-04-01 14:58:38 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:05:43 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 16:05:44 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 16:05:44 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2058, in block_thread
2024-04-01 16:05:44 | ERROR | stderr |     time.sleep(0.1)
2024-04-01 16:05:44 | ERROR | stderr | KeyboardInterrupt
2024-04-01 16:05:44 | ERROR | stderr | 
2024-04-01 16:05:44 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-01 16:05:44 | ERROR | stderr | 
2024-04-01 16:05:44 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 16:05:44 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 47, in <module>
2024-04-01 16:05:44 | ERROR | stderr |     host = "0.0.0.0"
2024-04-01 16:05:44 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1975, in launch
2024-04-01 16:05:44 | ERROR | stderr |     self.block_thread()
2024-04-01 16:05:44 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2061, in block_thread
2024-04-01 16:05:44 | ERROR | stderr |     self.server.close()
2024-04-01 16:05:44 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/networking.py", line 43, in close
2024-04-01 16:05:44 | ERROR | stderr |     self.thread.join()
2024-04-01 16:05:44 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-01 16:05:44 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-01 16:05:44 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-01 16:05:44 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-01 16:05:44 | ERROR | stderr | KeyboardInterrupt
2024-04-01 16:05:52 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 16:05:52 | INFO | stdout | 
2024-04-01 16:05:52 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 16:06:02 | INFO | stdout | []
2024-04-01 16:06:02 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:06:02 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 16:06:02 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-01 16:06:02 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-01 16:06:02 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1352, in process_api
2024-04-01 16:06:02 | ERROR | stderr |     result = await self.call_function(
2024-04-01 16:06:02 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1077, in call_function
2024-04-01 16:06:02 | ERROR | stderr |     prediction = await anyio.to_thread.run_sync(
2024-04-01 16:06:02 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/to_thread.py", line 56, in run_sync
2024-04-01 16:06:02 | ERROR | stderr |     return await get_async_backend().run_sync_in_worker_thread(
2024-04-01 16:06:02 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 2134, in run_sync_in_worker_thread
2024-04-01 16:06:02 | ERROR | stderr |     return await future
2024-04-01 16:06:02 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 851, in run
2024-04-01 16:06:02 | ERROR | stderr |     result = context.run(func, *args)
2024-04-01 16:06:02 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 14, in submit_file
2024-04-01 16:06:02 | ERROR | stderr |     worker.list_file += file_paths
2024-04-01 16:06:02 | ERROR | stderr | AttributeError: 'ModelWorker' object has no attribute 'list_file'
2024-04-01 16:06:21 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 16:06:21 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 16:06:21 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2058, in block_thread
2024-04-01 16:06:21 | ERROR | stderr |     time.sleep(0.1)
2024-04-01 16:06:21 | ERROR | stderr | KeyboardInterrupt
2024-04-01 16:06:21 | ERROR | stderr | 
2024-04-01 16:06:21 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-01 16:06:21 | ERROR | stderr | 
2024-04-01 16:06:21 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 16:06:21 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 56, in <module>
2024-04-01 16:06:21 | ERROR | stderr |     demo.queue(
2024-04-01 16:06:21 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1975, in launch
2024-04-01 16:06:21 | ERROR | stderr |     self.block_thread()
2024-04-01 16:06:21 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2061, in block_thread
2024-04-01 16:06:21 | ERROR | stderr |     self.server.close()
2024-04-01 16:06:21 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/networking.py", line 43, in close
2024-04-01 16:06:21 | ERROR | stderr |     self.thread.join()
2024-04-01 16:06:21 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-01 16:06:21 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-01 16:06:21 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-01 16:06:21 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-01 16:06:21 | ERROR | stderr | KeyboardInterrupt
2024-04-01 16:06:28 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 16:06:28 | INFO | stdout | 
2024-04-01 16:06:28 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 16:06:33 | INFO | stdout | []
2024-04-01 16:06:33 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:06:37 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:06:37 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:06:46 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:06:46 | INFO | stdout | ['Project_QA-Friday.pdf', 'Project_QA-Sunday.pdf']
2024-04-01 16:06:47 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:06:47 | INFO | stdout | ['Project_QA-Friday.pdf', 'Project_QA-Sunday.pdf']
2024-04-01 16:06:48 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:06:48 | INFO | stdout | ['Project_QA-Friday.pdf', 'Project_QA-Sunday.pdf']
2024-04-01 16:18:56 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 16:18:56 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 16:18:56 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2058, in block_thread
2024-04-01 16:18:56 | ERROR | stderr |     time.sleep(0.1)
2024-04-01 16:18:56 | ERROR | stderr | KeyboardInterrupt
2024-04-01 16:18:56 | ERROR | stderr | 
2024-04-01 16:18:56 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-01 16:18:56 | ERROR | stderr | 
2024-04-01 16:18:56 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 16:18:56 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 56, in <module>
2024-04-01 16:18:56 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1975, in launch
2024-04-01 16:18:56 | ERROR | stderr |     self.block_thread()
2024-04-01 16:18:56 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2061, in block_thread
2024-04-01 16:18:56 | ERROR | stderr |     self.server.close()
2024-04-01 16:18:56 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/networking.py", line 43, in close
2024-04-01 16:18:56 | ERROR | stderr |     self.thread.join()
2024-04-01 16:18:56 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-01 16:18:56 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-01 16:18:56 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-01 16:18:56 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-01 16:18:56 | ERROR | stderr | KeyboardInterrupt
2024-04-01 16:19:17 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 16:19:17 | INFO | stdout | 
2024-04-01 16:19:17 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 16:20:06 | INFO | stdout | []
2024-04-01 16:20:06 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 16:20:06 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-01 16:20:06 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-01 16:20:06 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1352, in process_api
2024-04-01 16:20:06 | ERROR | stderr |     result = await self.call_function(
2024-04-01 16:20:06 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1077, in call_function
2024-04-01 16:20:06 | ERROR | stderr |     prediction = await anyio.to_thread.run_sync(
2024-04-01 16:20:06 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/to_thread.py", line 56, in run_sync
2024-04-01 16:20:06 | ERROR | stderr |     return await get_async_backend().run_sync_in_worker_thread(
2024-04-01 16:20:06 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 2134, in run_sync_in_worker_thread
2024-04-01 16:20:06 | ERROR | stderr |     return await future
2024-04-01 16:20:06 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 851, in run
2024-04-01 16:20:06 | ERROR | stderr |     result = context.run(func, *args)
2024-04-01 16:20:06 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 12, in submit_file
2024-04-01 16:20:06 | ERROR | stderr |     file_paths = [os.path.basename(file.name) for file in files]
2024-04-01 16:20:06 | ERROR | stderr | TypeError: 'NoneType' object is not iterable
2024-04-01 16:20:15 | INFO | stdout | []
2024-04-01 16:20:15 | INFO | stdout | ['Project_QA-Friday.pdf', 'Project_QA-Sunday.pdf']
2024-04-01 16:20:15 | INFO | stdout | []
2024-04-01 16:20:15 | INFO | stdout | ['Project_QA-Friday.pdf', 'Project_QA-Sunday.pdf']
2024-04-01 16:23:32 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 16:23:32 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 16:23:32 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2058, in block_thread
2024-04-01 16:23:32 | ERROR | stderr |     time.sleep(0.1)
2024-04-01 16:23:32 | ERROR | stderr | KeyboardInterrupt
2024-04-01 16:23:32 | ERROR | stderr | 
2024-04-01 16:23:32 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-01 16:23:32 | ERROR | stderr | 
2024-04-01 16:23:32 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 16:23:32 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 59, in <module>
2024-04-01 16:23:32 | ERROR | stderr |     worker = ModelWorker()
2024-04-01 16:23:32 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1975, in launch
2024-04-01 16:23:32 | ERROR | stderr |     self.block_thread()
2024-04-01 16:23:32 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2061, in block_thread
2024-04-01 16:23:32 | ERROR | stderr |     self.server.close()
2024-04-01 16:23:32 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/networking.py", line 43, in close
2024-04-01 16:23:32 | ERROR | stderr |     self.thread.join()
2024-04-01 16:23:32 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-01 16:23:32 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-01 16:23:32 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-01 16:23:32 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-01 16:23:32 | ERROR | stderr | KeyboardInterrupt
2024-04-01 16:23:50 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 16:23:50 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 60, in <module>
2024-04-01 16:23:50 | ERROR | stderr |     demo = build_demo()
2024-04-01 16:23:50 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 37, in build_demo
2024-04-01 16:23:50 | ERROR | stderr |     submit_button.click(submit_file, [file_output, file_checkbox], [file_checkbox])
2024-04-01 16:23:50 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/events.py", line 143, in __call__
2024-04-01 16:23:50 | ERROR | stderr |     dep, dep_index = self.trigger.set_event_trigger(
2024-04-01 16:23:50 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 226, in set_event_trigger
2024-04-01 16:23:50 | ERROR | stderr |     raise AttributeError(
2024-04-01 16:23:50 | ERROR | stderr | AttributeError: click() and other events can only be called within a Blocks context.
2024-04-01 16:26:23 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 16:26:23 | INFO | stdout | 
2024-04-01 16:26:23 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 16:26:49 | INFO | stdout | []
2024-04-01 16:26:49 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:26:50 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:26:50 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:26:50 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:26:50 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:26:51 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:26:51 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:26:51 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:26:51 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:26:52 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:26:52 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:26:52 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:26:52 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:26:53 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:26:53 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:26:53 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:26:53 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:26:54 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:26:54 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:26:54 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:26:54 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-01 16:27:02 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 16:29:38 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 16:29:38 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 67, in <module>
2024-04-01 16:29:38 | ERROR | stderr |     demo = build_demo()
2024-04-01 16:29:38 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 37, in build_demo
2024-04-01 16:29:38 | ERROR | stderr |     submit_button.click(submit_file, [file_output, file_checkbox], [file_checkbox])
2024-04-01 16:29:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/events.py", line 143, in __call__
2024-04-01 16:29:38 | ERROR | stderr |     dep, dep_index = self.trigger.set_event_trigger(
2024-04-01 16:29:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 226, in set_event_trigger
2024-04-01 16:29:38 | ERROR | stderr |     raise AttributeError(
2024-04-01 16:29:38 | ERROR | stderr | AttributeError: click() and other events can only be called within a Blocks context.
2024-04-01 16:30:32 | INFO | stdout | <gradio.layouts.Row object at 0x7f749302f430>
2024-04-01 16:30:32 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 16:30:32 | INFO | stdout | 
2024-04-01 16:30:32 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 16:32:12 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 16:32:40 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 16:32:40 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 68, in <module>
2024-04-01 16:32:40 | ERROR | stderr |     demo = build_demo()
2024-04-01 16:32:40 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 46, in build_demo
2024-04-01 16:32:40 | ERROR | stderr |     print(demo_collection.btn_submit)
2024-04-01 16:32:40 | ERROR | stderr | AttributeError: 'Row' object has no attribute 'btn_submit'
2024-04-01 16:34:59 | INFO | stdout | <gradio.layouts.Row object at 0x7fbc21fb6730>
2024-04-01 16:34:59 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 16:34:59 | INFO | stdout | 
2024-04-01 16:34:59 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 16:35:09 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 16:35:24 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 16:35:24 | INFO | stdout | 
2024-04-01 16:35:24 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 16:35:51 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 16:36:10 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 16:36:10 | INFO | stdout | 
2024-04-01 16:36:10 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 16:38:22 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 16:38:35 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 16:38:35 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 68, in <module>
2024-04-01 16:38:35 | ERROR | stderr |     demo = build_demo()
2024-04-01 16:38:35 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 45, in build_demo
2024-04-01 16:38:35 | ERROR | stderr |     collection_1.render()
2024-04-01 16:38:35 | ERROR | stderr | NameError: name 'collection_1' is not defined
2024-04-01 16:39:42 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 16:39:42 | INFO | stdout | 
2024-04-01 16:39:42 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 16:42:04 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 16:47:03 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:766: UserWarning: Expected 1 arguments for function <function create_collection at 0x7f62e65428b0>, received 0.
2024-04-01 16:47:03 | ERROR | stderr |   warnings.warn(
2024-04-01 16:47:03 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:770: UserWarning: Expected at least 1 arguments for function <function create_collection at 0x7f62e65428b0>, received 0.
2024-04-01 16:47:03 | ERROR | stderr |   warnings.warn(
2024-04-01 16:47:03 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 16:47:03 | INFO | stdout | 
2024-04-01 16:47:03 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 16:47:24 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 16:47:37 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 16:47:37 | INFO | stdout | 
2024-04-01 16:47:37 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 16:48:00 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 16:48:09 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 16:48:09 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 75, in <module>
2024-04-01 16:48:09 | ERROR | stderr |     demo = build_demo()
2024-04-01 16:48:09 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 51, in build_demo
2024-04-01 16:48:09 | ERROR | stderr |     create_collection_button.click(create_collection, ["cl1"], result_row)
2024-04-01 16:48:09 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/events.py", line 143, in __call__
2024-04-01 16:48:09 | ERROR | stderr |     dep, dep_index = self.trigger.set_event_trigger(
2024-04-01 16:48:09 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 270, in set_event_trigger
2024-04-01 16:48:09 | ERROR | stderr |     "inputs": [block._id for block in inputs],
2024-04-01 16:48:09 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 270, in <listcomp>
2024-04-01 16:48:09 | ERROR | stderr |     "inputs": [block._id for block in inputs],
2024-04-01 16:48:09 | ERROR | stderr | AttributeError: 'str' object has no attribute '_id'
2024-04-01 16:48:45 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 16:48:45 | INFO | stdout | 
2024-04-01 16:48:45 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 16:48:50 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 16:48:50 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-01 16:48:50 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-01 16:48:50 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1355, in process_api
2024-04-01 16:48:50 | ERROR | stderr |     data = self.postprocess_data(fn_index, result["prediction"], state)
2024-04-01 16:48:50 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1286, in postprocess_data
2024-04-01 16:48:50 | ERROR | stderr |     assert isinstance(
2024-04-01 16:48:50 | ERROR | stderr | AssertionError: <class 'gradio.layouts.Row'> Component with id 6 not a valid output component.
2024-04-01 16:48:55 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 16:49:16 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 16:49:16 | INFO | stdout | 
2024-04-01 16:49:16 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 16:49:18 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 16:49:18 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-01 16:49:18 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-01 16:49:18 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1355, in process_api
2024-04-01 16:49:18 | ERROR | stderr |     data = self.postprocess_data(fn_index, result["prediction"], state)
2024-04-01 16:49:18 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1286, in postprocess_data
2024-04-01 16:49:18 | ERROR | stderr |     assert isinstance(
2024-04-01 16:49:18 | ERROR | stderr | AssertionError: <class 'gradio.layouts.Row'> Component with id 6 not a valid output component.
2024-04-01 16:55:50 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 16:56:01 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 16:56:01 | INFO | stdout | 
2024-04-01 16:56:01 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 16:56:07 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 16:56:07 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-01 16:56:07 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-01 16:56:07 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1355, in process_api
2024-04-01 16:56:07 | ERROR | stderr |     data = self.postprocess_data(fn_index, result["prediction"], state)
2024-04-01 16:56:07 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1286, in postprocess_data
2024-04-01 16:56:07 | ERROR | stderr |     assert isinstance(
2024-04-01 16:56:07 | ERROR | stderr | AssertionError: <class 'gradio.layouts.Row'> Component with id 6 not a valid output component.
2024-04-01 16:56:32 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 16:56:52 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 16:56:52 | INFO | stdout | 
2024-04-01 16:56:52 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 16:57:23 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 16:57:33 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 16:57:33 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 75, in <module>
2024-04-01 16:57:33 | ERROR | stderr |     demo = build_demo()
2024-04-01 16:57:33 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 51, in build_demo
2024-04-01 16:57:33 | ERROR | stderr |     create_collection_button.click(create_collection, [], [demo_collection])
2024-04-01 16:57:33 | ERROR | stderr | NameError: name 'demo_collection' is not defined
2024-04-01 16:57:47 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 16:57:47 | INFO | stdout | 
2024-04-01 16:57:47 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 16:57:56 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 16:57:56 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-01 16:57:56 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-01 16:57:56 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1355, in process_api
2024-04-01 16:57:56 | ERROR | stderr |     data = self.postprocess_data(fn_index, result["prediction"], state)
2024-04-01 16:57:56 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1286, in postprocess_data
2024-04-01 16:57:56 | ERROR | stderr |     assert isinstance(
2024-04-01 16:57:56 | ERROR | stderr | AssertionError: <class 'gradio.layouts.Row'> Component with id 6 not a valid output component.
2024-04-01 16:58:21 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 16:58:35 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 16:58:35 | INFO | stdout | 
2024-04-01 16:58:35 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 16:58:38 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 16:58:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-01 16:58:38 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-01 16:58:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1352, in process_api
2024-04-01 16:58:38 | ERROR | stderr |     result = await self.call_function(
2024-04-01 16:58:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1077, in call_function
2024-04-01 16:58:38 | ERROR | stderr |     prediction = await anyio.to_thread.run_sync(
2024-04-01 16:58:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/to_thread.py", line 56, in run_sync
2024-04-01 16:58:38 | ERROR | stderr |     return await get_async_backend().run_sync_in_worker_thread(
2024-04-01 16:58:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 2134, in run_sync_in_worker_thread
2024-04-01 16:58:38 | ERROR | stderr |     return await future
2024-04-01 16:58:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 851, in run
2024-04-01 16:58:38 | ERROR | stderr |     result = context.run(func, *args)
2024-04-01 16:58:38 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 25, in create_collection
2024-04-01 16:58:38 | ERROR | stderr |     return gr.CheckboxGroup.update(elem_id="collection_1")
2024-04-01 16:58:38 | ERROR | stderr | TypeError: update() got an unexpected keyword argument 'elem_id'
2024-04-01 16:59:12 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 16:59:41 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 16:59:41 | INFO | stdout | 
2024-04-01 16:59:41 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 17:00:00 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 17:00:14 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 17:00:14 | INFO | stdout | 
2024-04-01 17:00:14 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 17:00:34 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 17:00:53 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 17:00:53 | INFO | stdout | 
2024-04-01 17:00:53 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 17:00:55 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 17:00:55 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-01 17:00:55 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-01 17:00:55 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1355, in process_api
2024-04-01 17:00:55 | ERROR | stderr |     data = self.postprocess_data(fn_index, result["prediction"], state)
2024-04-01 17:00:55 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1286, in postprocess_data
2024-04-01 17:00:55 | ERROR | stderr |     assert isinstance(
2024-04-01 17:00:55 | ERROR | stderr | AssertionError: <class 'gradio.layouts.Row'> Component with id 6 not a valid output component.
2024-04-01 17:02:54 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 17:03:14 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 17:03:14 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 75, in <module>
2024-04-01 17:03:14 | ERROR | stderr |     demo = build_demo()
2024-04-01 17:03:14 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 51, in build_demo
2024-04-01 17:03:14 | ERROR | stderr |     create_collection_button.click(create_collection, [], [result_row.render()])
2024-04-01 17:03:14 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 112, in render
2024-04-01 17:03:14 | ERROR | stderr |     raise DuplicateBlockError(
2024-04-01 17:03:14 | ERROR | stderr | gradio.exceptions.DuplicateBlockError: A block with id: 6 has already been rendered in the current Blocks.
2024-04-01 17:06:48 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 17:06:48 | INFO | stdout | 
2024-04-01 17:06:48 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 17:07:15 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 17:07:24 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 17:07:24 | INFO | stdout | 
2024-04-01 17:07:24 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 17:07:27 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 17:07:27 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-01 17:07:27 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-01 17:07:27 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1352, in process_api
2024-04-01 17:07:27 | ERROR | stderr |     result = await self.call_function(
2024-04-01 17:07:27 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1077, in call_function
2024-04-01 17:07:27 | ERROR | stderr |     prediction = await anyio.to_thread.run_sync(
2024-04-01 17:07:27 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/to_thread.py", line 56, in run_sync
2024-04-01 17:07:27 | ERROR | stderr |     return await get_async_backend().run_sync_in_worker_thread(
2024-04-01 17:07:27 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 2134, in run_sync_in_worker_thread
2024-04-01 17:07:27 | ERROR | stderr |     return await future
2024-04-01 17:07:27 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 851, in run
2024-04-01 17:07:27 | ERROR | stderr |     result = context.run(func, *args)
2024-04-01 17:07:27 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 19, in create_collection
2024-04-01 17:07:27 | ERROR | stderr |     with gr.Row(elem_id="collection_1", variant="panel").update() as demo_collection:
2024-04-01 17:07:27 | ERROR | stderr | AttributeError: __enter__
2024-04-01 17:08:19 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 17:08:34 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 17:08:34 | INFO | stdout | 
2024-04-01 17:08:34 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 17:08:38 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 17:08:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-01 17:08:38 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-01 17:08:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1352, in process_api
2024-04-01 17:08:38 | ERROR | stderr |     result = await self.call_function(
2024-04-01 17:08:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1077, in call_function
2024-04-01 17:08:38 | ERROR | stderr |     prediction = await anyio.to_thread.run_sync(
2024-04-01 17:08:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/to_thread.py", line 56, in run_sync
2024-04-01 17:08:38 | ERROR | stderr |     return await get_async_backend().run_sync_in_worker_thread(
2024-04-01 17:08:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 2134, in run_sync_in_worker_thread
2024-04-01 17:08:38 | ERROR | stderr |     return await future
2024-04-01 17:08:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 851, in run
2024-04-01 17:08:38 | ERROR | stderr |     result = context.run(func, *args)
2024-04-01 17:08:38 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 25, in create_collection
2024-04-01 17:08:38 | ERROR | stderr |     return demo_collection.update(elem_id="collection_1", variant="panel")
2024-04-01 17:08:38 | ERROR | stderr | TypeError: update() got an unexpected keyword argument 'elem_id'
2024-04-01 17:08:49 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 17:08:56 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 17:08:56 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 76, in <module>
2024-04-01 17:08:56 | ERROR | stderr |     demo = build_demo()
2024-04-01 17:08:56 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 50, in build_demo
2024-04-01 17:08:56 | ERROR | stderr |     result_row.render()
2024-04-01 17:08:56 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 112, in render
2024-04-01 17:08:56 | ERROR | stderr |     raise DuplicateBlockError(
2024-04-01 17:08:56 | ERROR | stderr | gradio.exceptions.DuplicateBlockError: A block with id: 6 has already been rendered in the current Blocks.
2024-04-01 17:09:24 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 17:09:24 | INFO | stdout | 
2024-04-01 17:09:24 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 17:10:00 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 17:10:48 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 17:10:48 | INFO | stdout | 
2024-04-01 17:10:48 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 17:11:41 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 17:11:41 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 17:11:41 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2058, in block_thread
2024-04-01 17:11:41 | ERROR | stderr |     time.sleep(0.1)
2024-04-01 17:11:41 | ERROR | stderr | KeyboardInterrupt
2024-04-01 17:11:41 | ERROR | stderr | 
2024-04-01 17:11:41 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-01 17:11:41 | ERROR | stderr | 
2024-04-01 17:11:41 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 17:11:41 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 78, in <module>
2024-04-01 17:11:41 | ERROR | stderr |     demo = build_demo()
2024-04-01 17:11:41 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1975, in launch
2024-04-01 17:11:41 | ERROR | stderr |     self.block_thread()
2024-04-01 17:11:41 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2061, in block_thread
2024-04-01 17:11:41 | ERROR | stderr |     self.server.close()
2024-04-01 17:11:41 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/networking.py", line 43, in close
2024-04-01 17:11:41 | ERROR | stderr |     self.thread.join()
2024-04-01 17:11:41 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-01 17:11:41 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-01 17:11:41 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-01 17:11:41 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-01 17:11:41 | ERROR | stderr | KeyboardInterrupt
2024-04-01 17:11:48 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 17:11:48 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 78, in <module>
2024-04-01 17:11:48 | ERROR | stderr |     demo = build_demo()
2024-04-01 17:11:48 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 54, in build_demo
2024-04-01 17:11:48 | ERROR | stderr |     result_row.render()
2024-04-01 17:11:48 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 112, in render
2024-04-01 17:11:48 | ERROR | stderr |     raise DuplicateBlockError(
2024-04-01 17:11:48 | ERROR | stderr | gradio.exceptions.DuplicateBlockError: A block with id: 4 has already been rendered in the current Blocks.
2024-04-01 17:14:12 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-01 17:14:12 | INFO | stdout | 
2024-04-01 17:14:12 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-01 17:16:29 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-01 17:16:29 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 17:16:29 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2058, in block_thread
2024-04-01 17:16:29 | ERROR | stderr |     time.sleep(0.1)
2024-04-01 17:16:29 | ERROR | stderr | KeyboardInterrupt
2024-04-01 17:16:29 | ERROR | stderr | 
2024-04-01 17:16:29 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-01 17:16:29 | ERROR | stderr | 
2024-04-01 17:16:29 | ERROR | stderr | Traceback (most recent call last):
2024-04-01 17:16:29 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 84, in <module>
2024-04-01 17:16:29 | ERROR | stderr |     demo.queue(
2024-04-01 17:16:29 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1975, in launch
2024-04-01 17:16:29 | ERROR | stderr |     self.block_thread()
2024-04-01 17:16:29 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2061, in block_thread
2024-04-01 17:16:29 | ERROR | stderr |     self.server.close()
2024-04-01 17:16:29 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/networking.py", line 43, in close
2024-04-01 17:16:29 | ERROR | stderr |     self.thread.join()
2024-04-01 17:16:29 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-01 17:16:29 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-01 17:16:29 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-01 17:16:29 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-01 17:16:29 | ERROR | stderr | KeyboardInterrupt
2024-04-02 09:10:26 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 09:10:26 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 97, in <module>
2024-04-02 09:10:26 | ERROR | stderr |     demo = build_demo()
2024-04-02 09:10:26 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 54, in build_demo
2024-04-02 09:10:26 | ERROR | stderr |     file_checkbox.render()
2024-04-02 09:10:26 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 112, in render
2024-04-02 09:10:26 | ERROR | stderr |     raise DuplicateBlockError(
2024-04-02 09:10:26 | ERROR | stderr | gradio.exceptions.DuplicateBlockError: A block with id: 1 has already been rendered in the current Blocks.
2024-04-02 09:13:55 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 09:13:55 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 97, in <module>
2024-04-02 09:13:55 | ERROR | stderr |     demo = build_demo()
2024-04-02 09:13:55 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 84, in build_demo
2024-04-02 09:13:55 | ERROR | stderr |     create_collection_button.click(create_collection, [collection_count], \
2024-04-02 09:13:55 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/events.py", line 143, in __call__
2024-04-02 09:13:55 | ERROR | stderr |     dep, dep_index = self.trigger.set_event_trigger(
2024-04-02 09:13:55 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 270, in set_event_trigger
2024-04-02 09:13:55 | ERROR | stderr |     "inputs": [block._id for block in inputs],
2024-04-02 09:13:55 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 270, in <listcomp>
2024-04-02 09:13:55 | ERROR | stderr |     "inputs": [block._id for block in inputs],
2024-04-02 09:13:55 | ERROR | stderr | AttributeError: 'int' object has no attribute '_id'
2024-04-02 09:15:47 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:766: UserWarning: Expected 1 arguments for function <function create_collection at 0x7f0e5585aca0>, received 0.
2024-04-02 09:15:47 | ERROR | stderr |   warnings.warn(
2024-04-02 09:15:47 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:770: UserWarning: Expected at least 1 arguments for function <function create_collection at 0x7f0e5585aca0>, received 0.
2024-04-02 09:15:47 | ERROR | stderr |   warnings.warn(
2024-04-02 09:15:47 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 09:15:47 | INFO | stdout | 
2024-04-02 09:15:47 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 09:15:52 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 09:15:52 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 09:15:52 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2058, in block_thread
2024-04-02 09:15:52 | ERROR | stderr |     time.sleep(0.1)
2024-04-02 09:15:52 | ERROR | stderr | KeyboardInterrupt
2024-04-02 09:15:52 | ERROR | stderr | 
2024-04-02 09:15:52 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-02 09:15:52 | ERROR | stderr | 
2024-04-02 09:15:52 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 09:15:52 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 100, in <module>
2024-04-02 09:15:52 | ERROR | stderr |     demo.queue(
2024-04-02 09:15:52 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1975, in launch
2024-04-02 09:15:52 | ERROR | stderr |     self.block_thread()
2024-04-02 09:15:52 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2061, in block_thread
2024-04-02 09:15:52 | ERROR | stderr |     self.server.close()
2024-04-02 09:15:52 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/networking.py", line 43, in close
2024-04-02 09:15:52 | ERROR | stderr |     self.thread.join()
2024-04-02 09:15:52 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-02 09:15:52 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-02 09:15:52 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-02 09:15:52 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-02 09:15:52 | ERROR | stderr | KeyboardInterrupt
2024-04-02 09:16:10 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 09:16:10 | INFO | stdout | 
2024-04-02 09:16:10 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 09:16:20 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 09:16:20 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-02 09:16:20 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-02 09:16:20 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1352, in process_api
2024-04-02 09:16:20 | ERROR | stderr |     result = await self.call_function(
2024-04-02 09:16:20 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1077, in call_function
2024-04-02 09:16:20 | ERROR | stderr |     prediction = await anyio.to_thread.run_sync(
2024-04-02 09:16:20 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/to_thread.py", line 56, in run_sync
2024-04-02 09:16:20 | ERROR | stderr |     return await get_async_backend().run_sync_in_worker_thread(
2024-04-02 09:16:20 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 2134, in run_sync_in_worker_thread
2024-04-02 09:16:20 | ERROR | stderr |     return await future
2024-04-02 09:16:20 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 851, in run
2024-04-02 09:16:20 | ERROR | stderr |     result = context.run(func, *args)
2024-04-02 09:16:20 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 19, in create_collection
2024-04-02 09:16:20 | ERROR | stderr |     collection_count += 1
2024-04-02 09:16:20 | ERROR | stderr | UnboundLocalError: local variable 'collection_count' referenced before assignment
2024-04-02 09:16:28 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 09:16:28 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 09:16:28 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2058, in block_thread
2024-04-02 09:16:28 | ERROR | stderr |     time.sleep(0.1)
2024-04-02 09:16:28 | ERROR | stderr | KeyboardInterrupt
2024-04-02 09:16:28 | ERROR | stderr | 
2024-04-02 09:16:28 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-02 09:16:28 | ERROR | stderr | 
2024-04-02 09:16:28 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 09:16:28 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 100, in <module>
2024-04-02 09:16:28 | ERROR | stderr |     demo.queue(
2024-04-02 09:16:28 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1975, in launch
2024-04-02 09:16:28 | ERROR | stderr |     self.block_thread()
2024-04-02 09:16:28 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2061, in block_thread
2024-04-02 09:16:28 | ERROR | stderr |     self.server.close()
2024-04-02 09:16:28 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/networking.py", line 43, in close
2024-04-02 09:16:28 | ERROR | stderr |     self.thread.join()
2024-04-02 09:16:28 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-02 09:16:28 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-02 09:16:28 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-02 09:16:28 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-02 09:16:28 | ERROR | stderr | KeyboardInterrupt
2024-04-02 09:16:48 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 09:16:48 | INFO | stdout | 
2024-04-02 09:16:48 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 09:17:03 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 09:17:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-02 09:17:03 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-02 09:17:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1352, in process_api
2024-04-02 09:17:03 | ERROR | stderr |     result = await self.call_function(
2024-04-02 09:17:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1077, in call_function
2024-04-02 09:17:03 | ERROR | stderr |     prediction = await anyio.to_thread.run_sync(
2024-04-02 09:17:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/to_thread.py", line 56, in run_sync
2024-04-02 09:17:03 | ERROR | stderr |     return await get_async_backend().run_sync_in_worker_thread(
2024-04-02 09:17:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 2134, in run_sync_in_worker_thread
2024-04-02 09:17:03 | ERROR | stderr |     return await future
2024-04-02 09:17:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 851, in run
2024-04-02 09:17:03 | ERROR | stderr |     result = context.run(func, *args)
2024-04-02 09:17:03 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 19, in create_collection
2024-04-02 09:17:03 | ERROR | stderr |     collection_count += 1
2024-04-02 09:17:03 | ERROR | stderr | UnboundLocalError: local variable 'collection_count' referenced before assignment
2024-04-02 09:17:47 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 09:17:52 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 09:17:52 | INFO | stdout | 
2024-04-02 09:17:52 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 09:17:58 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 09:17:58 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-02 09:17:58 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-02 09:17:58 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1352, in process_api
2024-04-02 09:17:58 | ERROR | stderr |     result = await self.call_function(
2024-04-02 09:17:58 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1077, in call_function
2024-04-02 09:17:58 | ERROR | stderr |     prediction = await anyio.to_thread.run_sync(
2024-04-02 09:17:58 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/to_thread.py", line 56, in run_sync
2024-04-02 09:17:58 | ERROR | stderr |     return await get_async_backend().run_sync_in_worker_thread(
2024-04-02 09:17:58 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 2134, in run_sync_in_worker_thread
2024-04-02 09:17:58 | ERROR | stderr |     return await future
2024-04-02 09:17:58 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 851, in run
2024-04-02 09:17:58 | ERROR | stderr |     result = context.run(func, *args)
2024-04-02 09:17:58 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 22, in create_collection
2024-04-02 09:17:58 | ERROR | stderr |     return (collection_count) + (gr.Row.update(visible=True))*collection_count + (gr.Row.update(visible=False))*(5-collection_count)
2024-04-02 09:17:58 | ERROR | stderr | TypeError: unsupported operand type(s) for *: 'dict' and 'int'
2024-04-02 09:18:29 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 09:18:36 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 09:18:36 | INFO | stdout | 
2024-04-02 09:18:36 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 09:19:53 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 09:20:11 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 09:20:11 | INFO | stdout | 
2024-04-02 09:20:11 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 09:21:48 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 09:21:49 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 09:21:49 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2058, in block_thread
2024-04-02 09:21:49 | ERROR | stderr |     time.sleep(0.1)
2024-04-02 09:21:49 | ERROR | stderr | KeyboardInterrupt
2024-04-02 09:21:49 | ERROR | stderr | 
2024-04-02 09:21:49 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-02 09:21:49 | ERROR | stderr | 
2024-04-02 09:21:49 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 09:21:49 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 103, in <module>
2024-04-02 09:21:49 | ERROR | stderr |     collection_count = 0
2024-04-02 09:21:49 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1975, in launch
2024-04-02 09:21:49 | ERROR | stderr |     self.block_thread()
2024-04-02 09:21:49 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2061, in block_thread
2024-04-02 09:21:49 | ERROR | stderr |     self.server.close()
2024-04-02 09:21:49 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/networking.py", line 43, in close
2024-04-02 09:21:49 | ERROR | stderr |     self.thread.join()
2024-04-02 09:21:49 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-02 09:21:49 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-02 09:21:49 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-02 09:21:49 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-02 09:21:49 | ERROR | stderr | KeyboardInterrupt
2024-04-02 09:22:05 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 09:22:05 | INFO | stdout | 
2024-04-02 09:22:05 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 09:23:21 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 09:23:34 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 09:23:34 | INFO | stdout | 
2024-04-02 09:23:34 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 09:24:24 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 09:24:35 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 09:24:35 | INFO | stdout | 
2024-04-02 09:24:35 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 09:27:59 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 09:28:08 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 09:28:08 | INFO | stdout | 
2024-04-02 09:28:08 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 09:28:27 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 09:28:38 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 09:28:38 | INFO | stdout | 
2024-04-02 09:28:38 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 09:29:03 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 09:29:03 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 09:29:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2058, in block_thread
2024-04-02 09:29:03 | ERROR | stderr |     time.sleep(0.1)
2024-04-02 09:29:03 | ERROR | stderr | KeyboardInterrupt
2024-04-02 09:29:03 | ERROR | stderr | 
2024-04-02 09:29:03 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-02 09:29:03 | ERROR | stderr | 
2024-04-02 09:29:03 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 09:29:03 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 111, in <module>
2024-04-02 09:29:03 | ERROR | stderr |     demo.queue(
2024-04-02 09:29:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1975, in launch
2024-04-02 09:29:03 | ERROR | stderr |     self.block_thread()
2024-04-02 09:29:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2061, in block_thread
2024-04-02 09:29:03 | ERROR | stderr |     self.server.close()
2024-04-02 09:29:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/networking.py", line 43, in close
2024-04-02 09:29:03 | ERROR | stderr |     self.thread.join()
2024-04-02 09:29:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-02 09:29:03 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-02 09:29:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-02 09:29:03 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-02 09:29:03 | ERROR | stderr | KeyboardInterrupt
2024-04-02 09:29:22 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 09:29:22 | INFO | stdout | 
2024-04-02 09:29:22 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 09:29:43 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 09:29:51 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 09:29:51 | INFO | stdout | 
2024-04-02 09:29:51 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 09:33:49 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 09:34:08 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 09:34:08 | INFO | stdout | 
2024-04-02 09:34:08 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 09:34:41 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 09:34:54 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 09:34:54 | INFO | stdout | 
2024-04-02 09:34:54 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 09:35:30 | INFO | stdout | []
2024-04-02 09:35:30 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-02 09:35:31 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-02 09:35:31 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-02 09:35:31 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-02 09:35:31 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-02 09:35:32 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-02 09:35:32 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-02 09:35:32 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-02 09:35:32 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-02 09:35:32 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-02 09:35:32 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-02 09:35:36 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 09:38:40 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 09:38:40 | INFO | stdout | 
2024-04-02 09:38:40 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 09:38:52 | INFO | stdout | []
2024-04-02 09:38:52 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 09:38:52 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-02 09:38:52 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-02 09:38:52 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1352, in process_api
2024-04-02 09:38:52 | ERROR | stderr |     result = await self.call_function(
2024-04-02 09:38:52 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1077, in call_function
2024-04-02 09:38:52 | ERROR | stderr |     prediction = await anyio.to_thread.run_sync(
2024-04-02 09:38:52 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/to_thread.py", line 56, in run_sync
2024-04-02 09:38:52 | ERROR | stderr |     return await get_async_backend().run_sync_in_worker_thread(
2024-04-02 09:38:52 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 2134, in run_sync_in_worker_thread
2024-04-02 09:38:52 | ERROR | stderr |     return await future
2024-04-02 09:38:52 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 851, in run
2024-04-02 09:38:52 | ERROR | stderr |     result = context.run(func, *args)
2024-04-02 09:38:52 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 12, in submit_file
2024-04-02 09:38:52 | ERROR | stderr |     file_paths = [os.path.basename(file.name) for file in files]
2024-04-02 09:38:52 | ERROR | stderr | TypeError: 'NoneType' object is not iterable
2024-04-02 09:39:00 | INFO | stdout | []
2024-04-02 09:39:00 | INFO | stdout | ['Project_QA-Friday.pdf', 'Project_QA-Sunday.pdf']
2024-04-02 09:39:01 | INFO | stdout | ['Project_QA-Friday.pdf', 'Project_QA-Sunday.pdf']
2024-04-02 09:39:01 | INFO | stdout | ['Project_QA-Friday.pdf', 'Project_QA-Sunday.pdf']
2024-04-02 09:40:01 | INFO | stdout | []
2024-04-02 09:40:01 | INFO | stdout | ['8496_GIAO-TRINH-TT-HCM.pdf', 'QuocphongVietNam2019.pdf']
2024-04-02 09:40:10 | INFO | stdout | ['Project_QA-Friday.pdf', 'Project_QA-Sunday.pdf', 'Project_QA-Friday.pdf', 'Project_QA-Sunday.pdf', '8496_GIAO-TRINH-TT-HCM.pdf', 'QuocphongVietNam2019.pdf']
2024-04-02 09:40:10 | INFO | stdout | ['8496_GIAO-TRINH-TT-HCM.pdf', 'QuocphongVietNam2019.pdf']
2024-04-02 09:40:12 | INFO | stdout | ['Project_QA-Friday.pdf', 'Project_QA-Sunday.pdf', 'Project_QA-Friday.pdf', 'Project_QA-Sunday.pdf']
2024-04-02 09:40:12 | INFO | stdout | ['Project_QA-Friday.pdf', 'Project_QA-Sunday.pdf']
2024-04-02 09:48:41 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 09:49:01 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:766: UserWarning: Expected 3 arguments for function <function submit_file at 0x7fa91b23e0d0>, received 2.
2024-04-02 09:49:01 | ERROR | stderr |   warnings.warn(
2024-04-02 09:49:01 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:770: UserWarning: Expected at least 3 arguments for function <function submit_file at 0x7fa91b23e0d0>, received 2.
2024-04-02 09:49:01 | ERROR | stderr |   warnings.warn(
2024-04-02 09:49:01 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 09:49:01 | INFO | stdout | 
2024-04-02 09:49:01 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 09:53:36 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 09:53:36 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-02 09:53:36 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-02 09:53:36 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1350, in process_api
2024-04-02 09:53:36 | ERROR | stderr |     inputs = self.preprocess_data(fn_index, inputs, state)
2024-04-02 09:53:36 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1194, in preprocess_data
2024-04-02 09:53:36 | ERROR | stderr |     assert isinstance(
2024-04-02 09:53:36 | ERROR | stderr | AssertionError: <class 'gradio.layouts.Row'> Component with id 4 not a valid input component.
2024-04-02 09:56:03 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 09:56:03 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 09:56:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2058, in block_thread
2024-04-02 09:56:03 | ERROR | stderr |     time.sleep(0.1)
2024-04-02 09:56:03 | ERROR | stderr | KeyboardInterrupt
2024-04-02 09:56:03 | ERROR | stderr | 
2024-04-02 09:56:03 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-02 09:56:03 | ERROR | stderr | 
2024-04-02 09:56:03 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 09:56:03 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 124, in <module>
2024-04-02 09:56:03 | ERROR | stderr |     demo.queue(
2024-04-02 09:56:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1975, in launch
2024-04-02 09:56:03 | ERROR | stderr |     self.block_thread()
2024-04-02 09:56:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2061, in block_thread
2024-04-02 09:56:03 | ERROR | stderr |     self.server.close()
2024-04-02 09:56:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/networking.py", line 43, in close
2024-04-02 09:56:03 | ERROR | stderr |     self.thread.join()
2024-04-02 09:56:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-02 09:56:03 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-02 09:56:03 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-02 09:56:03 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-02 09:56:03 | ERROR | stderr | KeyboardInterrupt
2024-04-02 09:56:21 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 09:56:21 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 123, in <module>
2024-04-02 09:56:21 | ERROR | stderr |     demo = build_demo()
2024-04-02 09:56:21 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 61, in build_demo
2024-04-02 09:56:21 | ERROR | stderr |     submit_button1.click(submit_file, [file_output1, file_checkbox1, "collection_1"], [file_checkbox1])
2024-04-02 09:56:21 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/events.py", line 143, in __call__
2024-04-02 09:56:21 | ERROR | stderr |     dep, dep_index = self.trigger.set_event_trigger(
2024-04-02 09:56:21 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 270, in set_event_trigger
2024-04-02 09:56:21 | ERROR | stderr |     "inputs": [block._id for block in inputs],
2024-04-02 09:56:21 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 270, in <listcomp>
2024-04-02 09:56:21 | ERROR | stderr |     "inputs": [block._id for block in inputs],
2024-04-02 09:56:21 | ERROR | stderr | AttributeError: 'str' object has no attribute '_id'
2024-04-02 09:58:29 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:766: UserWarning: Expected 3 arguments for function <function submit_file at 0x7f692d3b80d0>, received 2.
2024-04-02 09:58:29 | ERROR | stderr |   warnings.warn(
2024-04-02 09:58:29 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:770: UserWarning: Expected at least 3 arguments for function <function submit_file at 0x7f692d3b80d0>, received 2.
2024-04-02 09:58:29 | ERROR | stderr |   warnings.warn(
2024-04-02 09:58:29 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 09:58:29 | INFO | stdout | 
2024-04-02 09:58:29 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 09:58:37 | INFO | stdout | <h1>Collection 1</h1>
2024-04-02 09:58:37 | INFO | stdout | 
2024-04-02 09:58:37 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf']
2024-04-02 09:58:37 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 09:58:37 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-02 09:58:37 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-02 09:58:37 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1352, in process_api
2024-04-02 09:58:37 | ERROR | stderr |     result = await self.call_function(
2024-04-02 09:58:37 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1077, in call_function
2024-04-02 09:58:37 | ERROR | stderr |     prediction = await anyio.to_thread.run_sync(
2024-04-02 09:58:37 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/to_thread.py", line 56, in run_sync
2024-04-02 09:58:37 | ERROR | stderr |     return await get_async_backend().run_sync_in_worker_thread(
2024-04-02 09:58:37 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 2134, in run_sync_in_worker_thread
2024-04-02 09:58:37 | ERROR | stderr |     return await future
2024-04-02 09:58:37 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 851, in run
2024-04-02 09:58:37 | ERROR | stderr |     result = context.run(func, *args)
2024-04-02 09:58:37 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 19, in submit_file
2024-04-02 09:58:37 | ERROR | stderr |     worker.get_list_file += file_paths
2024-04-02 09:58:37 | ERROR | stderr | TypeError: unsupported operand type(s) for +=: 'method' and 'list'
2024-04-02 10:00:54 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 10:01:05 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:766: UserWarning: Expected 3 arguments for function <function submit_file at 0x7f7422d9e0d0>, received 2.
2024-04-02 10:01:05 | ERROR | stderr |   warnings.warn(
2024-04-02 10:01:05 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:770: UserWarning: Expected at least 3 arguments for function <function submit_file at 0x7f7422d9e0d0>, received 2.
2024-04-02 10:01:05 | ERROR | stderr |   warnings.warn(
2024-04-02 10:01:05 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 10:01:05 | INFO | stdout | 
2024-04-02 10:01:05 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 10:01:16 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 10:01:16 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-02 10:01:16 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-02 10:01:16 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1352, in process_api
2024-04-02 10:01:16 | ERROR | stderr |     result = await self.call_function(
2024-04-02 10:01:16 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1077, in call_function
2024-04-02 10:01:16 | ERROR | stderr |     prediction = await anyio.to_thread.run_sync(
2024-04-02 10:01:16 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/to_thread.py", line 56, in run_sync
2024-04-02 10:01:16 | ERROR | stderr |     return await get_async_backend().run_sync_in_worker_thread(
2024-04-02 10:01:16 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 2134, in run_sync_in_worker_thread
2024-04-02 10:01:16 | ERROR | stderr |     return await future
2024-04-02 10:01:16 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 851, in run
2024-04-02 10:01:16 | ERROR | stderr |     result = context.run(func, *args)
2024-04-02 10:01:16 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 16, in submit_file
2024-04-02 10:01:16 | ERROR | stderr |     print(name_collection.value)
2024-04-02 10:01:16 | ERROR | stderr | AttributeError: 'str' object has no attribute 'value'
2024-04-02 10:03:00 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 10:03:15 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 10:03:15 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 3, in <module>
2024-04-02 10:03:15 | ERROR | stderr |     import html2text
2024-04-02 10:03:15 | ERROR | stderr | ModuleNotFoundError: No module named 'html2text'
2024-04-02 10:03:59 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 10:03:59 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 3, in <module>
2024-04-02 10:03:59 | ERROR | stderr |     import html2text
2024-04-02 10:03:59 | ERROR | stderr | ModuleNotFoundError: No module named 'html2text'
2024-04-02 10:07:52 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 10:07:52 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 3, in <module>
2024-04-02 10:07:52 | ERROR | stderr |     import html2text
2024-04-02 10:07:52 | ERROR | stderr | ModuleNotFoundError: No module named 'html2text'
2024-04-02 10:08:08 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:766: UserWarning: Expected 3 arguments for function <function submit_file at 0x7fcbfe0ac0d0>, received 2.
2024-04-02 10:08:08 | ERROR | stderr |   warnings.warn(
2024-04-02 10:08:08 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:770: UserWarning: Expected at least 3 arguments for function <function submit_file at 0x7fcbfe0ac0d0>, received 2.
2024-04-02 10:08:08 | ERROR | stderr |   warnings.warn(
2024-04-02 10:08:08 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 10:08:08 | INFO | stdout | 
2024-04-02 10:08:08 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 10:08:17 | INFO | stdout | []
2024-04-02 10:08:17 | INFO | stdout | ['CV-HoÃ ng VÅ© An-AI.pdf']
2024-04-02 10:08:17 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 10:08:17 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-02 10:08:17 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-02 10:08:17 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1352, in process_api
2024-04-02 10:08:17 | ERROR | stderr |     result = await self.call_function(
2024-04-02 10:08:17 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1077, in call_function
2024-04-02 10:08:17 | ERROR | stderr |     prediction = await anyio.to_thread.run_sync(
2024-04-02 10:08:17 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/to_thread.py", line 56, in run_sync
2024-04-02 10:08:17 | ERROR | stderr |     return await get_async_backend().run_sync_in_worker_thread(
2024-04-02 10:08:17 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 2134, in run_sync_in_worker_thread
2024-04-02 10:08:17 | ERROR | stderr |     return await future
2024-04-02 10:08:17 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 851, in run
2024-04-02 10:08:17 | ERROR | stderr |     result = context.run(func, *args)
2024-04-02 10:08:17 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 21, in submit_file
2024-04-02 10:08:17 | ERROR | stderr |     worker.get_list_file += file_paths
2024-04-02 10:08:17 | ERROR | stderr | TypeError: unsupported operand type(s) for +=: 'method' and 'list'
2024-04-02 10:08:39 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 10:08:57 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:766: UserWarning: Expected 3 arguments for function <function submit_file at 0x7f401dd7e0d0>, received 2.
2024-04-02 10:08:57 | ERROR | stderr |   warnings.warn(
2024-04-02 10:08:57 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:770: UserWarning: Expected at least 3 arguments for function <function submit_file at 0x7f401dd7e0d0>, received 2.
2024-04-02 10:08:57 | ERROR | stderr |   warnings.warn(
2024-04-02 10:08:57 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 10:08:57 | INFO | stdout | 
2024-04-02 10:08:57 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 10:09:14 | INFO | stdout | <h1>Collection 1</h1>
2024-04-02 10:09:14 | INFO | stdout | 
2024-04-02 10:09:14 | INFO | stdout | ['Collection 1']
2024-04-02 10:09:14 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf']
2024-04-02 10:09:14 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 10:09:14 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-02 10:09:14 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-02 10:09:14 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1352, in process_api
2024-04-02 10:09:14 | ERROR | stderr |     result = await self.call_function(
2024-04-02 10:09:14 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1077, in call_function
2024-04-02 10:09:14 | ERROR | stderr |     prediction = await anyio.to_thread.run_sync(
2024-04-02 10:09:14 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/to_thread.py", line 56, in run_sync
2024-04-02 10:09:14 | ERROR | stderr |     return await get_async_backend().run_sync_in_worker_thread(
2024-04-02 10:09:14 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 2134, in run_sync_in_worker_thread
2024-04-02 10:09:14 | ERROR | stderr |     return await future
2024-04-02 10:09:14 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 851, in run
2024-04-02 10:09:14 | ERROR | stderr |     result = context.run(func, *args)
2024-04-02 10:09:14 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 22, in submit_file
2024-04-02 10:09:14 | ERROR | stderr |     worker.get_list_file += file_paths
2024-04-02 10:09:14 | ERROR | stderr | TypeError: unsupported operand type(s) for +=: 'method' and 'list'
2024-04-02 10:13:17 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 10:17:35 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 10:17:35 | INFO | stdout | 
2024-04-02 10:17:35 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 10:17:50 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf']
2024-04-02 10:17:50 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 10:17:50 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-02 10:17:50 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-02 10:17:50 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1352, in process_api
2024-04-02 10:17:50 | ERROR | stderr |     result = await self.call_function(
2024-04-02 10:17:50 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1077, in call_function
2024-04-02 10:17:50 | ERROR | stderr |     prediction = await anyio.to_thread.run_sync(
2024-04-02 10:17:50 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/to_thread.py", line 56, in run_sync
2024-04-02 10:17:50 | ERROR | stderr |     return await get_async_backend().run_sync_in_worker_thread(
2024-04-02 10:17:50 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 2134, in run_sync_in_worker_thread
2024-04-02 10:17:50 | ERROR | stderr |     return await future
2024-04-02 10:17:50 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 851, in run
2024-04-02 10:17:50 | ERROR | stderr |     result = context.run(func, *args)
2024-04-02 10:17:50 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 23, in submit_file
2024-04-02 10:17:50 | ERROR | stderr |     res = worker.add_list_file(name_collection, file_paths)
2024-04-02 10:17:50 | ERROR | stderr | TypeError: add_list_file() takes 2 positional arguments but 3 were given
2024-04-02 10:18:05 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 10:18:12 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 10:18:12 | INFO | stdout | 
2024-04-02 10:18:12 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 10:18:28 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf']
2024-04-02 10:18:30 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf']
2024-04-02 10:18:36 | INFO | stdout | ['VÄƒn Quang - AI Engineer.pdf']
2024-04-02 10:18:37 | INFO | stdout | ['VÄƒn Quang - AI Engineer.pdf']
2024-04-02 10:18:45 | INFO | stdout | ['future_ai.pdf']
2024-04-02 10:18:46 | INFO | stdout | ['future_ai.pdf']
2024-04-02 10:18:53 | INFO | stdout | ['Nguyen Hai Lam- AI Engineer.pdf']
2024-04-02 10:21:27 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 10:21:46 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 10:21:46 | INFO | stdout | 
2024-04-02 10:21:46 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 10:26:06 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 10:26:23 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 10:26:23 | INFO | stdout | 
2024-04-02 10:26:23 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 10:27:27 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 10:27:37 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 10:27:37 | INFO | stdout | 
2024-04-02 10:27:37 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 10:27:46 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf']
2024-04-02 10:27:47 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf']
2024-04-02 10:27:53 | INFO | stdout | ['BQP.pdf']
2024-04-02 10:27:54 | INFO | stdout | ['BQP.pdf']
2024-04-02 10:27:54 | INFO | stdout | ['BQP.pdf']
2024-04-02 10:27:54 | INFO | stdout | ['BQP.pdf']
2024-04-02 10:27:55 | INFO | stdout | ['BQP.pdf']
2024-04-02 10:27:59 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'BQP.pdf']
2024-04-02 10:27:59 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'BQP.pdf']
2024-04-02 10:28:00 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'BQP.pdf']
2024-04-02 10:30:42 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'BQP.pdf']
2024-04-02 10:30:55 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 10:31:15 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 10:31:15 | INFO | stdout | 
2024-04-02 10:31:15 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 10:32:36 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf']
2024-04-02 10:32:36 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf']
2024-04-02 10:32:36 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf']
2024-04-02 10:32:36 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf']
2024-04-02 10:32:47 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'BQP.pdf']
2024-04-02 10:32:47 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf']
2024-04-02 10:32:48 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'BQP.pdf']
2024-04-02 10:32:48 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'BQP.pdf']
2024-04-02 10:32:50 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'BQP.pdf']
2024-04-02 10:32:50 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'BQP.pdf', 'BQP.pdf']
2024-04-02 10:32:53 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'BQP.pdf']
2024-04-02 10:32:53 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'BQP.pdf', 'BQP.pdf', 'BQP.pdf']
2024-04-02 10:35:25 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 10:35:25 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 10:35:25 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2058, in block_thread
2024-04-02 10:35:25 | ERROR | stderr |     time.sleep(0.1)
2024-04-02 10:35:25 | ERROR | stderr | KeyboardInterrupt
2024-04-02 10:35:25 | ERROR | stderr | 
2024-04-02 10:35:25 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-02 10:35:25 | ERROR | stderr | 
2024-04-02 10:35:25 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 10:35:25 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 131, in <module>
2024-04-02 10:35:25 | ERROR | stderr |     demo.queue(
2024-04-02 10:35:25 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1975, in launch
2024-04-02 10:35:25 | ERROR | stderr |     self.block_thread()
2024-04-02 10:35:25 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2061, in block_thread
2024-04-02 10:35:25 | ERROR | stderr |     self.server.close()
2024-04-02 10:35:25 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/networking.py", line 43, in close
2024-04-02 10:35:25 | ERROR | stderr |     self.thread.join()
2024-04-02 10:35:25 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-02 10:35:25 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-02 10:35:25 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-02 10:35:25 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-02 10:35:25 | ERROR | stderr | KeyboardInterrupt
2024-04-02 10:35:44 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 10:35:44 | INFO | stdout | 
2024-04-02 10:35:44 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 10:35:54 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf']
2024-04-02 10:35:54 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf']
2024-04-02 10:35:54 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 10:35:54 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-02 10:35:54 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-02 10:35:54 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1352, in process_api
2024-04-02 10:35:54 | ERROR | stderr |     result = await self.call_function(
2024-04-02 10:35:54 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1077, in call_function
2024-04-02 10:35:54 | ERROR | stderr |     prediction = await anyio.to_thread.run_sync(
2024-04-02 10:35:54 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/to_thread.py", line 56, in run_sync
2024-04-02 10:35:54 | ERROR | stderr |     return await get_async_backend().run_sync_in_worker_thread(
2024-04-02 10:35:54 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 2134, in run_sync_in_worker_thread
2024-04-02 10:35:54 | ERROR | stderr |     return await future
2024-04-02 10:35:54 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 851, in run
2024-04-02 10:35:54 | ERROR | stderr |     result = context.run(func, *args)
2024-04-02 10:35:54 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 26, in submit_file
2024-04-02 10:35:54 | ERROR | stderr |     res = worker.add_list_file(name_collection, file_paths)
2024-04-02 10:35:54 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 14, in add_list_file
2024-04-02 10:35:54 | ERROR | stderr |     for i, file_name in reversed(enumerate(list_file)):
2024-04-02 10:35:54 | ERROR | stderr | TypeError: 'enumerate' object is not reversible
2024-04-02 10:36:05 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 10:36:05 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 10:36:05 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2058, in block_thread
2024-04-02 10:36:05 | ERROR | stderr |     time.sleep(0.1)
2024-04-02 10:36:05 | ERROR | stderr | KeyboardInterrupt
2024-04-02 10:36:05 | ERROR | stderr | 
2024-04-02 10:36:05 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-02 10:36:05 | ERROR | stderr | 
2024-04-02 10:36:05 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 10:36:05 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 131, in <module>
2024-04-02 10:36:05 | ERROR | stderr |     demo.queue(
2024-04-02 10:36:05 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1975, in launch
2024-04-02 10:36:05 | ERROR | stderr |     self.block_thread()
2024-04-02 10:36:05 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2061, in block_thread
2024-04-02 10:36:05 | ERROR | stderr |     self.server.close()
2024-04-02 10:36:05 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/networking.py", line 43, in close
2024-04-02 10:36:05 | ERROR | stderr |     self.thread.join()
2024-04-02 10:36:05 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-02 10:36:05 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-02 10:36:05 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-02 10:36:05 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-02 10:36:05 | ERROR | stderr | KeyboardInterrupt
2024-04-02 10:36:20 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 10:36:20 | INFO | stdout | 
2024-04-02 10:36:20 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 10:36:29 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf']
2024-04-02 10:36:29 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf']
2024-04-02 10:36:29 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf']
2024-04-02 10:36:29 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf']
2024-04-02 10:36:30 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf']
2024-04-02 10:36:30 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf']
2024-04-02 10:36:35 | INFO | stdout | ['BQP.pdf']
2024-04-02 10:36:35 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf']
2024-04-02 10:36:35 | INFO | stdout | ['BQP.pdf']
2024-04-02 10:36:35 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'BQP.pdf']
2024-04-02 10:36:36 | INFO | stdout | ['BQP.pdf']
2024-04-02 10:36:36 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'BQP.pdf']
2024-04-02 10:36:43 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-02 10:36:43 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'BQP.pdf']
2024-04-02 10:36:44 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-02 10:36:44 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf']
2024-04-02 10:36:44 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-02 10:36:44 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf']
2024-04-02 10:36:45 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-02 10:36:45 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf']
2024-04-02 10:36:45 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-02 10:36:45 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf']
2024-04-02 10:36:46 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf']
2024-04-02 10:36:46 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'BQP.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf']
2024-04-02 10:37:27 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf']
2024-04-02 10:37:27 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf']
2024-04-02 10:37:34 | INFO | stdout | ['BQP.pdf', 'VÄƒn Quang - AI Engineer.pdf']
2024-04-02 10:37:34 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf']
2024-04-02 10:37:34 | INFO | stdout | ['BQP.pdf', 'VÄƒn Quang - AI Engineer.pdf']
2024-04-02 10:37:34 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'VÄƒn Quang - AI Engineer.pdf']
2024-04-02 10:37:35 | INFO | stdout | ['BQP.pdf', 'VÄƒn Quang - AI Engineer.pdf']
2024-04-02 10:37:35 | INFO | stdout | ['Tay vÆ°Æ¡n camera_SB4.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf', 'BQP.pdf', 'VÄƒn Quang - AI Engineer.pdf']
2024-04-02 14:57:45 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 14:57:46 | ERROR | stderr | Error in sys.excepthook:
2024-04-02 14:57:46 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 14:57:46 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/exceptiongroup/_formatting.py", line 71, in exceptiongroup_excepthook
2024-04-02 14:57:46 | ERROR | stderr |     sys.stderr.write("".join(traceback.format_exception(etype, value, tb)))
2024-04-02 14:57:46 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/traceback.py", line 120, in format_exception
2024-04-02 14:57:46 | ERROR | stderr |     return list(TracebackException(
2024-04-02 14:57:46 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/exceptiongroup/_formatting.py", line 248, in format
2024-04-02 14:57:46 | ERROR | stderr |     yield from _ctx.emit(exc.format_exception_only())
2024-04-02 14:57:46 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/exceptiongroup/_formatting.py", line 64, in emit
2024-04-02 14:57:46 | ERROR | stderr |     for text in text_gen:
2024-04-02 14:57:46 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/exceptiongroup/_formatting.py", line 335, in format_exception_only
2024-04-02 14:57:46 | ERROR | stderr |     if isinstance(self.__notes__, collections.abc.Sequence):
2024-04-02 14:57:46 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/abc.py", line 119, in __instancecheck__
2024-04-02 14:57:46 | ERROR | stderr |     return _abc_instancecheck(cls, instance)
2024-04-02 14:57:46 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/abc.py", line 123, in __subclasscheck__
2024-04-02 14:57:46 | ERROR | stderr |     return _abc_subclasscheck(cls, subclass)
2024-04-02 14:57:46 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/abc.py", line 121, in __subclasscheck__
2024-04-02 14:57:46 | ERROR | stderr |     def __subclasscheck__(cls, subclass):
2024-04-02 14:57:46 | ERROR | stderr | KeyboardInterrupt
2024-04-02 14:57:46 | ERROR | stderr | 
2024-04-02 14:57:46 | ERROR | stderr | Original exception was:
2024-04-02 14:57:46 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 14:57:46 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2058, in block_thread
2024-04-02 14:57:46 | ERROR | stderr |     time.sleep(0.1)
2024-04-02 14:57:46 | ERROR | stderr | KeyboardInterrupt
2024-04-02 14:57:46 | ERROR | stderr | 
2024-04-02 14:57:46 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-02 14:57:46 | ERROR | stderr | 
2024-04-02 14:57:46 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 14:57:46 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 131, in <module>
2024-04-02 14:57:46 | ERROR | stderr |     global collection_count
2024-04-02 14:57:46 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1975, in launch
2024-04-02 14:57:46 | ERROR | stderr |     self.block_thread()
2024-04-02 14:57:46 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2061, in block_thread
2024-04-02 14:57:46 | ERROR | stderr |     self.server.close()
2024-04-02 14:57:46 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/networking.py", line 43, in close
2024-04-02 14:57:46 | ERROR | stderr |     self.thread.join()
2024-04-02 14:57:46 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-02 14:57:46 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-02 14:57:46 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-02 14:57:46 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-02 14:57:46 | ERROR | stderr | KeyboardInterrupt
2024-04-02 15:07:47 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:766: UserWarning: Expected 2 arguments for function <function submit_file at 0x7f92c0ac40d0>, received 3.
2024-04-02 15:07:47 | ERROR | stderr |   warnings.warn(
2024-04-02 15:07:47 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:774: UserWarning: Expected maximum 2 arguments for function <function submit_file at 0x7f92c0ac40d0>, received 3.
2024-04-02 15:07:47 | ERROR | stderr |   warnings.warn(
2024-04-02 15:07:47 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 15:07:47 | INFO | stdout | 
2024-04-02 15:07:47 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 15:09:49 | INFO | stdout | ['BQP.pdf']
2024-04-02 15:09:54 | INFO | stdout | ['VÄƒn Quang - AI Engineer.pdf', 'CV-HoÃ ng VÅ© An-AI.pdf']
2024-04-02 15:11:50 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 15:12:11 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:766: UserWarning: Expected 2 arguments for function <function submit_file at 0x7fa054fe80d0>, received 3.
2024-04-02 15:12:11 | ERROR | stderr |   warnings.warn(
2024-04-02 15:12:11 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:774: UserWarning: Expected maximum 2 arguments for function <function submit_file at 0x7fa054fe80d0>, received 3.
2024-04-02 15:12:11 | ERROR | stderr |   warnings.warn(
2024-04-02 15:12:11 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 15:12:11 | INFO | stdout | 
2024-04-02 15:12:11 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 15:13:30 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 15:13:50 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:766: UserWarning: Expected 2 arguments for function <function submit_file at 0x7f97bef9b0d0>, received 3.
2024-04-02 15:13:50 | ERROR | stderr |   warnings.warn(
2024-04-02 15:13:50 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:774: UserWarning: Expected maximum 2 arguments for function <function submit_file at 0x7f97bef9b0d0>, received 3.
2024-04-02 15:13:50 | ERROR | stderr |   warnings.warn(
2024-04-02 15:13:50 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 15:13:50 | INFO | stdout | 
2024-04-02 15:13:50 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 15:13:52 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 15:15:20 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:766: UserWarning: Expected 2 arguments for function <function submit_file at 0x7f54aad7c0d0>, received 3.
2024-04-02 15:15:20 | ERROR | stderr |   warnings.warn(
2024-04-02 15:15:20 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:774: UserWarning: Expected maximum 2 arguments for function <function submit_file at 0x7f54aad7c0d0>, received 3.
2024-04-02 15:15:20 | ERROR | stderr |   warnings.warn(
2024-04-02 15:15:20 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 15:15:20 | INFO | stdout | 
2024-04-02 15:15:20 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 15:15:38 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 15:15:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-02 15:15:38 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-02 15:15:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1352, in process_api
2024-04-02 15:15:38 | ERROR | stderr |     result = await self.call_function(
2024-04-02 15:15:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1077, in call_function
2024-04-02 15:15:38 | ERROR | stderr |     prediction = await anyio.to_thread.run_sync(
2024-04-02 15:15:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/to_thread.py", line 56, in run_sync
2024-04-02 15:15:38 | ERROR | stderr |     return await get_async_backend().run_sync_in_worker_thread(
2024-04-02 15:15:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 2134, in run_sync_in_worker_thread
2024-04-02 15:15:38 | ERROR | stderr |     return await future
2024-04-02 15:15:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 851, in run
2024-04-02 15:15:38 | ERROR | stderr |     result = context.run(func, *args)
2024-04-02 15:15:38 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 35, in delete_file
2024-04-02 15:15:38 | ERROR | stderr |     res = worker.delete_list_file(name_collection, file_paths)
2024-04-02 15:15:38 | ERROR | stderr | UnboundLocalError: local variable 'file_paths' referenced before assignment
2024-04-02 15:16:02 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 15:16:07 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:766: UserWarning: Expected 2 arguments for function <function submit_file at 0x7efc93f630d0>, received 3.
2024-04-02 15:16:07 | ERROR | stderr |   warnings.warn(
2024-04-02 15:16:07 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:774: UserWarning: Expected maximum 2 arguments for function <function submit_file at 0x7efc93f630d0>, received 3.
2024-04-02 15:16:07 | ERROR | stderr |   warnings.warn(
2024-04-02 15:16:07 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 15:16:07 | INFO | stdout | 
2024-04-02 15:16:07 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 15:16:21 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 15:16:21 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-02 15:16:21 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-02 15:16:21 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1352, in process_api
2024-04-02 15:16:21 | ERROR | stderr |     result = await self.call_function(
2024-04-02 15:16:21 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1077, in call_function
2024-04-02 15:16:21 | ERROR | stderr |     prediction = await anyio.to_thread.run_sync(
2024-04-02 15:16:21 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/to_thread.py", line 56, in run_sync
2024-04-02 15:16:21 | ERROR | stderr |     return await get_async_backend().run_sync_in_worker_thread(
2024-04-02 15:16:21 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 2134, in run_sync_in_worker_thread
2024-04-02 15:16:21 | ERROR | stderr |     return await future
2024-04-02 15:16:21 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 851, in run
2024-04-02 15:16:21 | ERROR | stderr |     result = context.run(func, *args)
2024-04-02 15:16:21 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 36, in delete_file
2024-04-02 15:16:21 | ERROR | stderr |     file_paths = worker.get_list_file(name_collection)
2024-04-02 15:16:21 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 9, in get_list_file
2024-04-02 15:16:21 | ERROR | stderr |     return self.list_collection[name_collection]
2024-04-02 15:16:21 | ERROR | stderr | KeyError: '<h1>Collection 1</h1>\n'
2024-04-02 15:16:42 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 15:17:03 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:766: UserWarning: Expected 2 arguments for function <function submit_file at 0x7f5a9e6140d0>, received 3.
2024-04-02 15:17:03 | ERROR | stderr |   warnings.warn(
2024-04-02 15:17:03 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:774: UserWarning: Expected maximum 2 arguments for function <function submit_file at 0x7f5a9e6140d0>, received 3.
2024-04-02 15:17:03 | ERROR | stderr |   warnings.warn(
2024-04-02 15:17:03 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 15:17:03 | INFO | stdout | 
2024-04-02 15:17:03 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 15:20:12 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 15:20:20 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:766: UserWarning: Expected 2 arguments for function <function submit_file at 0x7fc957e510d0>, received 3.
2024-04-02 15:20:20 | ERROR | stderr |   warnings.warn(
2024-04-02 15:20:20 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:774: UserWarning: Expected maximum 2 arguments for function <function submit_file at 0x7fc957e510d0>, received 3.
2024-04-02 15:20:20 | ERROR | stderr |   warnings.warn(
2024-04-02 15:20:20 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 15:20:20 | INFO | stdout | 
2024-04-02 15:20:20 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 15:21:08 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 15:21:08 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/routes.py", line 437, in run_predict
2024-04-02 15:21:08 | ERROR | stderr |     output = await app.get_blocks().process_api(
2024-04-02 15:21:08 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1352, in process_api
2024-04-02 15:21:08 | ERROR | stderr |     result = await self.call_function(
2024-04-02 15:21:08 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1077, in call_function
2024-04-02 15:21:08 | ERROR | stderr |     prediction = await anyio.to_thread.run_sync(
2024-04-02 15:21:08 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/to_thread.py", line 56, in run_sync
2024-04-02 15:21:08 | ERROR | stderr |     return await get_async_backend().run_sync_in_worker_thread(
2024-04-02 15:21:08 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 2134, in run_sync_in_worker_thread
2024-04-02 15:21:08 | ERROR | stderr |     return await future
2024-04-02 15:21:08 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/anyio/_backends/_asyncio.py", line 851, in run
2024-04-02 15:21:08 | ERROR | stderr |     result = context.run(func, *args)
2024-04-02 15:21:08 | ERROR | stderr | TypeError: submit_file() takes 2 positional arguments but 3 were given
2024-04-02 15:21:30 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 15:21:49 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 15:21:49 | INFO | stdout | 
2024-04-02 15:21:49 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 15:28:14 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 15:29:09 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 15:29:09 | INFO | stdout | 
2024-04-02 15:29:09 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 15:30:15 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 15:30:29 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 15:30:29 | INFO | stdout | 
2024-04-02 15:30:29 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 15:31:40 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 15:31:56 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 15:31:56 | INFO | stdout | 
2024-04-02 15:31:56 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 15:32:11 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 15:32:37 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 15:32:37 | INFO | stdout | 
2024-04-02 15:32:37 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 15:33:09 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 15:33:09 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 15:33:09 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2058, in block_thread
2024-04-02 15:33:09 | ERROR | stderr |     time.sleep(0.1)
2024-04-02 15:33:09 | ERROR | stderr | KeyboardInterrupt
2024-04-02 15:33:09 | ERROR | stderr | 
2024-04-02 15:33:09 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-02 15:33:09 | ERROR | stderr | 
2024-04-02 15:33:09 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 15:33:09 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 155, in <module>
2024-04-02 15:33:09 | ERROR | stderr |     demo.queue(
2024-04-02 15:33:09 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1975, in launch
2024-04-02 15:33:09 | ERROR | stderr |     self.block_thread()
2024-04-02 15:33:09 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2061, in block_thread
2024-04-02 15:33:09 | ERROR | stderr |     self.server.close()
2024-04-02 15:33:09 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/networking.py", line 43, in close
2024-04-02 15:33:09 | ERROR | stderr |     self.thread.join()
2024-04-02 15:33:09 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-02 15:33:09 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-02 15:33:09 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-02 15:33:09 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-02 15:33:09 | ERROR | stderr | KeyboardInterrupt
2024-04-02 15:33:18 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 15:33:18 | INFO | stdout | 
2024-04-02 15:33:18 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 15:33:30 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 15:33:30 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 15:33:30 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2058, in block_thread
2024-04-02 15:33:30 | ERROR | stderr |     time.sleep(0.1)
2024-04-02 15:33:30 | ERROR | stderr | KeyboardInterrupt
2024-04-02 15:33:30 | ERROR | stderr | 
2024-04-02 15:33:30 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-02 15:33:30 | ERROR | stderr | 
2024-04-02 15:33:30 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 15:33:30 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 155, in <module>
2024-04-02 15:33:30 | ERROR | stderr |     demo.queue(
2024-04-02 15:33:30 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1975, in launch
2024-04-02 15:33:30 | ERROR | stderr |     self.block_thread()
2024-04-02 15:33:30 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2061, in block_thread
2024-04-02 15:33:30 | ERROR | stderr |     self.server.close()
2024-04-02 15:33:30 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/networking.py", line 43, in close
2024-04-02 15:33:30 | ERROR | stderr |     self.thread.join()
2024-04-02 15:33:30 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-02 15:33:30 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-02 15:33:30 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-02 15:33:30 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-02 15:33:30 | ERROR | stderr | KeyboardInterrupt
2024-04-02 15:33:49 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 15:33:49 | INFO | stdout | 
2024-04-02 15:33:49 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 15:34:29 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 15:34:48 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 15:34:48 | INFO | stdout | 
2024-04-02 15:34:48 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 15:35:05 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 15:35:05 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 15:35:05 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2058, in block_thread
2024-04-02 15:35:05 | ERROR | stderr |     time.sleep(0.1)
2024-04-02 15:35:05 | ERROR | stderr | KeyboardInterrupt
2024-04-02 15:35:05 | ERROR | stderr | 
2024-04-02 15:35:05 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-02 15:35:05 | ERROR | stderr | 
2024-04-02 15:35:05 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 15:35:05 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 155, in <module>
2024-04-02 15:35:05 | ERROR | stderr |     demo.queue(
2024-04-02 15:35:05 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1975, in launch
2024-04-02 15:35:05 | ERROR | stderr |     self.block_thread()
2024-04-02 15:35:05 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2061, in block_thread
2024-04-02 15:35:05 | ERROR | stderr |     self.server.close()
2024-04-02 15:35:05 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/networking.py", line 43, in close
2024-04-02 15:35:05 | ERROR | stderr |     self.thread.join()
2024-04-02 15:35:05 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-02 15:35:05 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-02 15:35:05 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-02 15:35:05 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-02 15:35:05 | ERROR | stderr | KeyboardInterrupt
2024-04-02 15:35:19 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 15:35:19 | INFO | stdout | 
2024-04-02 15:35:19 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 15:35:38 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 15:36:01 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 15:36:01 | INFO | stdout | 
2024-04-02 15:36:01 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 15:37:27 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 15:37:27 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 15:37:27 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2058, in block_thread
2024-04-02 15:37:27 | ERROR | stderr |     time.sleep(0.1)
2024-04-02 15:37:27 | ERROR | stderr | KeyboardInterrupt
2024-04-02 15:37:27 | ERROR | stderr | 
2024-04-02 15:37:27 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-02 15:37:27 | ERROR | stderr | 
2024-04-02 15:37:27 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 15:37:27 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 156, in <module>
2024-04-02 15:37:27 | ERROR | stderr |     api_open = api_open,
2024-04-02 15:37:27 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1975, in launch
2024-04-02 15:37:27 | ERROR | stderr |     self.block_thread()
2024-04-02 15:37:27 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2061, in block_thread
2024-04-02 15:37:27 | ERROR | stderr |     self.server.close()
2024-04-02 15:37:27 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/networking.py", line 43, in close
2024-04-02 15:37:27 | ERROR | stderr |     self.thread.join()
2024-04-02 15:37:27 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-02 15:37:27 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-02 15:37:27 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-02 15:37:27 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-02 15:37:27 | ERROR | stderr | KeyboardInterrupt
2024-04-02 15:37:41 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 15:37:41 | INFO | stdout | 
2024-04-02 15:37:41 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 15:38:15 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 15:38:35 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 15:38:35 | INFO | stdout | 
2024-04-02 15:38:35 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 15:38:55 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 15:38:55 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 15:38:55 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2058, in block_thread
2024-04-02 15:38:55 | ERROR | stderr |     time.sleep(0.1)
2024-04-02 15:38:55 | ERROR | stderr | KeyboardInterrupt
2024-04-02 15:38:55 | ERROR | stderr | 
2024-04-02 15:38:55 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-02 15:38:55 | ERROR | stderr | 
2024-04-02 15:38:55 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 15:38:55 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 155, in <module>
2024-04-02 15:38:55 | ERROR | stderr |     demo.queue(
2024-04-02 15:38:55 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1975, in launch
2024-04-02 15:38:55 | ERROR | stderr |     self.block_thread()
2024-04-02 15:38:55 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2061, in block_thread
2024-04-02 15:38:55 | ERROR | stderr |     self.server.close()
2024-04-02 15:38:55 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/networking.py", line 43, in close
2024-04-02 15:38:55 | ERROR | stderr |     self.thread.join()
2024-04-02 15:38:55 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-02 15:38:55 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-02 15:38:55 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-02 15:38:55 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-02 15:38:55 | ERROR | stderr | KeyboardInterrupt
2024-04-02 15:39:13 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 15:39:13 | INFO | stdout | 
2024-04-02 15:39:13 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 15:39:37 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 15:39:37 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 15:39:37 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2058, in block_thread
2024-04-02 15:39:37 | ERROR | stderr |     time.sleep(0.1)
2024-04-02 15:39:37 | ERROR | stderr | KeyboardInterrupt
2024-04-02 15:39:37 | ERROR | stderr | 
2024-04-02 15:39:37 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-02 15:39:37 | ERROR | stderr | 
2024-04-02 15:39:37 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 15:39:37 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 155, in <module>
2024-04-02 15:39:37 | ERROR | stderr |     demo.queue(
2024-04-02 15:39:37 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1975, in launch
2024-04-02 15:39:37 | ERROR | stderr |     self.block_thread()
2024-04-02 15:39:37 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2061, in block_thread
2024-04-02 15:39:37 | ERROR | stderr |     self.server.close()
2024-04-02 15:39:37 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/networking.py", line 43, in close
2024-04-02 15:39:37 | ERROR | stderr |     self.thread.join()
2024-04-02 15:39:37 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-02 15:39:37 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-02 15:39:37 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-02 15:39:37 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-02 15:39:37 | ERROR | stderr | KeyboardInterrupt
2024-04-02 15:39:51 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 15:39:51 | INFO | stdout | 
2024-04-02 15:39:51 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 15:40:21 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 15:43:53 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:766: UserWarning: Expected 1 arguments for function <function create_collection at 0x7f192d3a8a60>, received 0.
2024-04-02 15:43:53 | ERROR | stderr |   warnings.warn(
2024-04-02 15:43:53 | ERROR | stderr | /home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/utils.py:770: UserWarning: Expected at least 1 arguments for function <function create_collection at 0x7f192d3a8a60>, received 0.
2024-04-02 15:43:53 | ERROR | stderr |   warnings.warn(
2024-04-02 15:43:53 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 15:43:53 | INFO | stdout | 
2024-04-02 15:43:53 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 15:59:36 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 15:59:45 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 15:59:45 | INFO | stdout | 
2024-04-02 15:59:45 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 16:00:34 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 16:00:55 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 16:00:55 | INFO | stdout | 
2024-04-02 16:00:55 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 16:01:23 | INFO | stdout | {'success': True}
2024-04-02 16:01:26 | INFO | stdout | {'success': True}
2024-04-02 16:31:43 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 16:31:43 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 16:31:43 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2058, in block_thread
2024-04-02 16:31:43 | ERROR | stderr |     time.sleep(0.1)
2024-04-02 16:31:43 | ERROR | stderr | KeyboardInterrupt
2024-04-02 16:31:43 | ERROR | stderr | 
2024-04-02 16:31:43 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-02 16:31:43 | ERROR | stderr | 
2024-04-02 16:31:43 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 16:31:43 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 156, in <module>
2024-04-02 16:31:43 | ERROR | stderr |     collection_count = 0
2024-04-02 16:31:43 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1975, in launch
2024-04-02 16:31:43 | ERROR | stderr |     self.block_thread()
2024-04-02 16:31:43 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2061, in block_thread
2024-04-02 16:31:43 | ERROR | stderr |     self.server.close()
2024-04-02 16:31:43 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/networking.py", line 43, in close
2024-04-02 16:31:43 | ERROR | stderr |     self.thread.join()
2024-04-02 16:31:43 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-02 16:31:43 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-02 16:31:43 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-02 16:31:43 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-02 16:31:43 | ERROR | stderr | KeyboardInterrupt
2024-04-02 16:31:57 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 16:31:57 | INFO | stdout | 
2024-04-02 16:31:57 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 16:49:50 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 16:49:50 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 16:49:50 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2058, in block_thread
2024-04-02 16:49:50 | ERROR | stderr |     time.sleep(0.1)
2024-04-02 16:49:50 | ERROR | stderr | KeyboardInterrupt
2024-04-02 16:49:50 | ERROR | stderr | 
2024-04-02 16:49:50 | ERROR | stderr | During handling of the above exception, another exception occurred:
2024-04-02 16:49:50 | ERROR | stderr | 
2024-04-02 16:49:50 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 16:49:50 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 160, in <module>
2024-04-02 16:49:50 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 1975, in launch
2024-04-02 16:49:50 | ERROR | stderr |     self.block_thread()
2024-04-02 16:49:50 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/blocks.py", line 2061, in block_thread
2024-04-02 16:49:50 | ERROR | stderr |     self.server.close()
2024-04-02 16:49:50 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/gradio/networking.py", line 43, in close
2024-04-02 16:49:50 | ERROR | stderr |     self.thread.join()
2024-04-02 16:49:50 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-02 16:49:50 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-02 16:49:50 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-02 16:49:50 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-02 16:49:50 | ERROR | stderr | KeyboardInterrupt
2024-04-02 16:49:50 | ERROR | stderr | Error in atexit._run_exitfuncs:
2024-04-02 16:49:50 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 16:49:50 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/torch/utils/data/_utils/__init__.py", line 45, in _set_python_exit_flag
2024-04-02 16:49:50 | ERROR | stderr |     def _set_python_exit_flag():
2024-04-02 16:49:50 | ERROR | stderr | KeyboardInterrupt
2024-04-02 16:50:15 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 16:50:15 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 3, in <module>
2024-04-02 16:50:15 | ERROR | stderr |     import chromadb
2024-04-02 16:50:15 | ERROR | stderr | ModuleNotFoundError: No module named 'chromadb'
2024-04-02 16:54:36 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 16:54:36 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 3, in <module>
2024-04-02 16:54:36 | ERROR | stderr |     import chromadb
2024-04-02 16:54:36 | ERROR | stderr | ModuleNotFoundError: No module named 'chromadb'
2024-04-02 16:56:03 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 16:56:03 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 3, in <module>
2024-04-02 16:56:03 | ERROR | stderr |     import chromadb
2024-04-02 16:56:03 | ERROR | stderr | ModuleNotFoundError: No module named 'chromadb'
2024-04-02 16:57:32 | INFO | stdout | <chromadb.api.client.Client object at 0x7fc844604fd0>
2024-04-02 16:57:33 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 16:57:33 | INFO | stdout | 
2024-04-02 16:57:33 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 16:58:08 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 16:58:08 | ERROR | stderr | Error in atexit._run_exitfuncs:
2024-04-02 16:58:08 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 16:58:08 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/posthog/client.py", line 416, in join
2024-04-02 16:58:08 | ERROR | stderr |     consumer.join()
2024-04-02 16:58:08 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-02 16:58:08 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-02 16:58:08 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-02 16:58:08 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-02 16:58:08 | ERROR | stderr | KeyboardInterrupt
2024-04-02 16:58:21 | INFO | stdout | <chromadb.api.client.Client object at 0x7f7cd4618040>
2024-04-02 16:58:21 | INFO | stdout | Running on local URL:  http://0.0.0.0:8887
2024-04-02 16:58:21 | INFO | stdout | 
2024-04-02 16:58:21 | INFO | stdout | To create a public link, set `share=True` in `launch()`.
2024-04-02 16:58:26 | INFO | stdout | <chromadb.api.client.Client object at 0x7f7cd4618040>
2024-04-02 16:58:28 | INFO | stdout | <chromadb.api.client.Client object at 0x7f7cd4618040>
2024-04-02 16:58:39 | INFO | stdout | Keyboard interruption in main thread... closing server.
2024-04-02 16:58:39 | ERROR | stderr | Error in atexit._run_exitfuncs:
2024-04-02 16:58:39 | ERROR | stderr | Traceback (most recent call last):
2024-04-02 16:58:39 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/posthog/client.py", line 416, in join
2024-04-02 16:58:39 | ERROR | stderr |     consumer.join()
2024-04-02 16:58:39 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1060, in join
2024-04-02 16:58:39 | ERROR | stderr |     self._wait_for_tstate_lock()
2024-04-02 16:58:39 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
2024-04-02 16:58:39 | ERROR | stderr |     if lock.acquire(block, timeout):
2024-04-02 16:58:39 | ERROR | stderr | KeyboardInterrupt
2024-04-03 09:49:38 | ERROR | stderr | Traceback (most recent call last):
2024-04-03 09:49:38 | ERROR | stderr |   File "/home/mq/disk2T/son/code/GitHub/MQ_GPT/src/app_knowledge.py", line 219, in <module>
2024-04-03 09:49:38 | ERROR | stderr |     embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=EMBED_MODEL)
2024-04-03 09:49:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/chromadb/utils/embedding_functions.py", line 72, in __init__
2024-04-03 09:49:38 | ERROR | stderr |     self.models[model_name] = SentenceTransformer(model_name, device=device)
2024-04-03 09:49:38 | ERROR | stderr |   File "/home/mq/anaconda3/envs/son_llm/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py", line 77, in __init__
2024-04-03 09:49:38 | ERROR | stderr |     raise ValueError("Path {} not found".format(model_name_or_path))
2024-04-03 09:49:38 | ERROR | stderr | ValueError: Path ./weights/all-mpnet-base-v2 not found
